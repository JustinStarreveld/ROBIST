{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2dd91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JSTARRE\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import mosek\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import phi_divergence as phi\n",
    "import robust_sampling as rs\n",
    "import dataio\n",
    "import util\n",
    "import scipy.stats\n",
    "from scipy.special import erfinv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21acbb",
   "metadata": {},
   "source": [
    "The problem we examine is as follows (from Esfahani, P., & Kuhn, D. (2018)):\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\label{math_form:examples:pm_exp}\n",
    "    \\min_{\\mathbf{x}}&~\\mathbb{E}( - \\mathbf{r}^T \\mathbf{x} ) + \\rho \\text{CVaR}_{\\alpha}(- \\mathbf{r}^T \\mathbf{x}) \\\\\n",
    "    \\text{s.t.}&~\\mathbf{e}^T \\mathbf{x} = 1, \\\\\n",
    "    &~\\mathbf{x} \\geq 0,\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "where $\\mathbf{x}, \\mathbf{r} \\in \\mathbb{R}^{k}$\n",
    "\n",
    "We follow their derivation and define $J$ as:\n",
    "\n",
    "$$J = \\max_{k=\\{1,2\\}} a_k \\mathbf{r}^T \\mathbf{x} + b_k \\tau$$,\n",
    "\n",
    "with $a_1=-1, a_2=-1-\\frac{\\rho}{\\alpha}, b_1=\\rho$ and $b_2=\\rho\\left(1-\\frac{1}{\\alpha}\\right)$.\n",
    "\n",
    "Then the objective is: $\\min_{\\mathbf{x}}~\\mathbb{E}[J]$. Which can be transformed to epigraph formulation:\n",
    "\\begin{align}\n",
    "\\label{}\n",
    "    \\min_{\\mathbf{x}, \\tau}&~\\theta \\\\\n",
    "    \\text{s.t.}&~\\mathbb{E}[J] \\leq \\theta,\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Filling in the definition of $J$ using variable $$\\gamma = J = \\max_{k=\\{1,2\\}} a_k \\mathbf{r}^T \\mathbf{x} + b_k \\tau$$ \n",
    "\n",
    "to replace the $\\max$ function, we rewrite the problem as follows:\n",
    "\n",
    "\\begin{align}\n",
    "\\label{math_form:examples:pm_exp_2}\n",
    "    \\min_{\\mathbf{x}, \\tau}&~\\theta \\\\\n",
    "    \\text{s.t.}&~\\mathbb{E}[\\gamma] \\leq \\theta, \\\\\n",
    "    &~- \\mathbf{r}^T \\mathbf{x} + \\rho \\tau \\leq \\gamma, \\\\\n",
    "    &~(-1-(\\rho / \\alpha)) \\mathbf{r}^T \\mathbf{x} + \\rho(1- (1 / \\alpha)) \\tau \\leq \\gamma, \\\\\n",
    "    &~\\mathbf{e}^T \\mathbf{x} = 1, \\\\\n",
    "    &~\\mathbf{x} \\geq 0, \\\\\n",
    "    &~\\tau, \\theta, \\gamma \\in \\mathbb{R},\n",
    "\\end{align}\n",
    "\n",
    "Thus we have an expected value constraint of the form $\\mathbb{E}[f(\\mathbf{r}, \\mathbf{x}^*)] \\leq 0$, with $f(\\mathbf{r}, \\mathbf{x}^*) = \\gamma - \\theta = \\max_{k=\\{1,2\\}} \\{a_k \\mathbf{r}^T \\mathbf{x} + b_k \\tau \\} - \\theta$\n",
    "\n",
    "In their numerical experiments, they set $k = 10$ and generate return by assuming normally distributed systematic + unsystematic risk factors. Furthermore, they set $\\alpha = 0.2$ and $\\rho = 10$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb43a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem specific functions:\n",
    "def generate_data(random_seed, m, N):\n",
    "    '''\n",
    "    Taken from:\n",
    "    https://nbviewer.org/github/MOSEK/Tutorials/blob/master/dist-robust-portfolio/Data-driven_distributionally_robust_portfolio.ipynb\n",
    "    '''\n",
    "    np.random.seed(random_seed)\n",
    "    R = np.vstack([np.random.normal(\n",
    "        i*0.03, np.sqrt((0.02**2+(i*0.025)**2)), N) for i in range(1, m+1)])\n",
    "    return (R.transpose())\n",
    "\n",
    "def generate_data_2(random_seed, m, N):\n",
    "    np.random.seed(random_seed)\n",
    "    # NOTE: not entirely clear in Esfahani & Kuhn paper whether they refer to stdev or var\n",
    "    sys_risk_mean = 0\n",
    "    #sys_risk_stdev = math.sqrt(0.02)\n",
    "    sys_risk_stdev = 0.02\n",
    "    unsys_risk_mean = np.fromiter(((i * 0.03) for i in range(1,k+1)), float)\n",
    "    #unsys_risk_stdev = np.fromiter(( math.sqrt(i * 0.025) for i in range(1,k+1)), float)\n",
    "    unsys_risk_stdev = np.fromiter(( i * 0.025 for i in range(1,k+1)), float)\n",
    "    \n",
    "    data = np.empty([N,k])\n",
    "    for n in range(0, N):\n",
    "        sys_return = np.random.normal(sys_risk_mean, sys_risk_stdev)\n",
    "        for i in range(0, k):\n",
    "            unsys_return = np.random.normal(unsys_risk_mean[i], unsys_risk_stdev[i])\n",
    "            data[n, i] = sys_return + unsys_return\n",
    "            \n",
    "    return data \n",
    "\n",
    "def solve_SCP(k, S, time_limit):\n",
    "    x = cp.Variable(k, nonneg = True)\n",
    "    theta = cp.Variable(1)\n",
    "    gamma = cp.Variable(1)\n",
    "    rho = 10 #TODO: fix this hardcode\n",
    "    CVaR_alpha = 0.20\n",
    "    tau = cp.Variable(1)\n",
    "    a_1 = -1\n",
    "    b_1 = rho\n",
    "    a_2 = -1 - (rho/CVaR_alpha)\n",
    "    b_2 = rho*(1 - (1/CVaR_alpha))\n",
    "    \n",
    "    constraints = [gamma - theta <= 0,\n",
    "                   a_1*(S @ x) + b_1*tau - gamma <= 0, \n",
    "                   a_2*(S @ x) + b_2*tau - gamma <= 0, \n",
    "                   cp.sum(x) == 1]\n",
    "    \n",
    "    obj = cp.Maximize(-theta) #equivalent to min \\theta\n",
    "    prob = cp.Problem(obj,constraints)\n",
    "    prob.solve(solver=cp.MOSEK, mosek_params = {mosek.dparam.optimizer_max_time: time_limit})\n",
    "    x_value = np.concatenate((theta.value,gamma.value,tau.value,x.value)) # Combine x, tau and theta into 1 single solution vector\n",
    "    return(x_value, prob.value)\n",
    "\n",
    "def uncertain_constraint(S, x):\n",
    "    rho = 10 #TODO: fix this hardcode\n",
    "    CVaR_alpha = 0.20\n",
    "    # Assume that x[1] contains gamma and x[2] contains tau\n",
    "    # Contrary to other applications, we have 2 uncertain constraints (because of max), the max{} should be <= 0\n",
    "    constr1 = -np.dot(S,x[3:]) + rho*x[2] - x[1]\n",
    "    constr2 = -(1+(rho/CVaR_alpha))*np.dot(S,x[3:]) + (rho*(1-(1/CVaR_alpha))*x[2]) - x[1] \n",
    "    return np.maximum(constr1, constr2)\n",
    "\n",
    "def check_robust(bound, numeric_precision, beta=0):\n",
    "    return (bound <= beta + numeric_precision)\n",
    "\n",
    "def emp_eval_obj(x, data, rho, CVaR_alpha):\n",
    "    x_sol = x[3:]\n",
    "    emp_returns = - (np.dot(data, x_sol))\n",
    "\n",
    "    exp_loss = np.mean(emp_returns, dtype=np.float64)\n",
    "    # print(exp_loss)\n",
    "    \n",
    "    VaR = np.quantile(emp_returns, 1-CVaR_alpha, method='inverted_cdf') # gets threshold for top CVaR_alpha-% highest losses\n",
    "    above_VaR = (emp_returns > VaR)\n",
    "    cVaR = np.mean(emp_returns[above_VaR])\n",
    "    # print(cVaR)\n",
    "    \n",
    "    return exp_loss + (rho*cVaR)\n",
    "\n",
    "def analytic_out_perf(x, rho, CVaR_alpha):\n",
    "    '''\n",
    "    https://nbviewer.org/github/MOSEK/Tutorials/blob/master/dist-robust-portfolio/Data-driven_distributionally_robust_portfolio.ipynb\n",
    "    Method to calculate the analytical value for the out-of-sample performance.\n",
    "    [see Rockafellar and Uryasev]\n",
    "    '''\n",
    "    x_sol = x[3:]\n",
    "    m = len(x_sol)\n",
    "    mu = np.arange(1, m+1)*0.03\n",
    "    var = 0.02 + (np.arange(1, m+1)*0.025)\n",
    "\n",
    "    # Constants for CVaR calculation.\n",
    "    rho = 10\n",
    "    beta = 1-CVaR_alpha\n",
    "    c2_beta = 1/(np.sqrt(2*np.pi)*(np.exp(erfinv(2*beta - 1))**2)*(1-beta))\n",
    "    \n",
    "    mean_loss = -np.dot(x_sol, mu)\n",
    "    # print(mean_loss)\n",
    "    sd_loss = np.sqrt(np.dot(x_sol**2, var))\n",
    "    cVaR = mean_loss + (sd_loss*c2_beta)\n",
    "    # print(cVaR)\n",
    "    return mean_loss + (rho*cVaR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb62b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_SCP_SAA(k, S, time_limit):\n",
    "    # hardcoded for now...\n",
    "    rho = 10 \n",
    "    CVaR_alpha = 0.20\n",
    "    a_1 = -1\n",
    "    b_1 = rho\n",
    "    a_2 = -1 - (rho/CVaR_alpha)\n",
    "    b_2 = rho*(1 - (1/CVaR_alpha))\n",
    "    N = S.shape[0]\n",
    "    \n",
    "    x = cp.Variable(k, nonneg = True)\n",
    "    theta = cp.Variable(1)\n",
    "    gamma = cp.Variable(N)\n",
    "    tau = cp.Variable(1)\n",
    "    \n",
    "    constraints = [(1/N)*cp.sum(gamma) - theta <= 0,\n",
    "                   a_1*(S @ x) + b_1*tau - gamma <= 0, \n",
    "                   a_2*(S @ x) + b_2*tau - gamma <= 0, \n",
    "                   cp.sum(x) == 1]\n",
    "    \n",
    "    obj = cp.Maximize(-theta) #equivalent to min \\theta\n",
    "    prob = cp.Problem(obj,constraints)\n",
    "    try:\n",
    "        prob.solve(solver=cp.MOSEK, \n",
    "                   # verbose=True,\n",
    "                   mosek_params = {mosek.dparam.optimizer_max_time: time_limit}\n",
    "                   )\n",
    "    except cp.error.SolverError:\n",
    "        print(\"Note: error occured in solving SAA problem...\")\n",
    "        return(None, float('-inf'))\n",
    "    # Combine x, tau and theta into 1 single solution vector\n",
    "    x_value = np.concatenate((theta.value,np.array([None]),tau.value,x.value))\n",
    "    return(x_value, prob.value)\n",
    "\n",
    "def uncertain_constraint_SAA(S, x):\n",
    "    # hardcoded for now...\n",
    "    rho = 10\n",
    "    CVaR_alpha = 0.20\n",
    "    a_1 = -1\n",
    "    b_1 = rho\n",
    "    a_2 = -1 - (rho/CVaR_alpha)\n",
    "    b_2 = rho*(1 - (1/CVaR_alpha))\n",
    "    N = S.shape[0]\n",
    "    \n",
    "    # Assume that x[1] contains gamma (vec of length N) and x[2] contains tau\n",
    "    # Contrary to other applications, we have 2 uncertain constraints (because of max)\n",
    "    # the max should be <= 0\n",
    "    constr1 = a_1*(S @ x[3:]) + b_1*x[2]\n",
    "    constr2 = a_2*(S @ x[3:]) + b_2*x[2]\n",
    "    return np.maximum(constr1, constr2) - x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c127a506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.833 -0.864\n",
      "-0.743 -1.139\n",
      "-0.27 -0.866\n",
      "0.178 -0.425\n",
      "0.394 -0.432\n",
      "-----------------------------\n",
      "-1.951 -0.864\n",
      "-1.344 -1.353\n",
      "-1.312 -1.356\n",
      "-1.364 -1.379\n",
      "-1.363 -1.387\n"
     ]
    }
   ],
   "source": [
    "# SCP vs SAA\n",
    "k = 10\n",
    "rho = 10\n",
    "CVaR_alpha = 0.20\n",
    "\n",
    "for N in [10, 100, 1000, 10000, 100000]:\n",
    "    data = generate_data_2(0, k, N)\n",
    "    sol, obj = solve_SCP(k, data, 10*60)\n",
    "    print(round(-obj,3), round(analytic_out_perf(sol, rho, CVaR_alpha),3))\n",
    "    \n",
    "print('-----------------------------')\n",
    "for N in [10, 100, 1000, 10000, 100000]:\n",
    "    data = generate_data_2(0, k, N)\n",
    "    sol, obj = solve_SCP_SAA(k, data, 10*60)\n",
    "    print(round(-obj,3), round(analytic_out_perf(sol, rho, CVaR_alpha),3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test obj eval functions with equal weighted portfolio:\n",
    "k = 10\n",
    "x = np.array([None, None, None] + [1/k for i in range(k)])\n",
    "rho = 10\n",
    "CVaR_alpha = 0.20\n",
    "\n",
    "for N in [1000000]:\n",
    "    data = generate_data(66 + 99, k, N)\n",
    "    obj_1 = emp_eval_obj(x, data, rho, CVaR_alpha)\n",
    "    print(obj_1)\n",
    "    \n",
    "    print(\"----------------\")\n",
    "    data_2 = generate_data_2(66 + 99, k, N)\n",
    "    obj_2 = emp_eval_obj(x, data_2, rho, CVaR_alpha)\n",
    "    print(obj_2)\n",
    "    \n",
    "    print(\"----------------\")\n",
    "    obj_3 = analytic_out_perf(x, rho, CVaR_alpha)\n",
    "    print(obj_3)\n",
    "\n",
    "# data gen 2 seems more accurate (if analytic_out_perf is correct)\n",
    "# Not sure why there is still a slight difference... \n",
    "# suspect that there is a mistake in analytic cVaR because empirical evaluation seems sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7922bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter values (as in Kuhn paper)\n",
    "k = 10\n",
    "rho = 10\n",
    "CVaR_alpha = 0.20\n",
    "risk_measure = 'exp_constraint_leq' # options: 'chance_constraint', 'exp_constraint'\n",
    "alpha = 0.50\n",
    "beta = 0\n",
    "N_total = 10000 # 30, 300, 3000\n",
    "N_train = int(N_total / 2)\n",
    "N_test = N_total - N_train\n",
    "num_obs_per_bin = max(N_test / 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set other parameter values\n",
    "par = 1\n",
    "phi_div = phi.mod_chi2_cut\n",
    "phi_dot = 2\n",
    "numeric_precision = 1e-6 # To correct for floating-point math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get generated data\n",
    "random_seed = 0\n",
    "data = generate_data(random_seed, k, N_total)   \n",
    "data_train, data_test = train_test_split(data, train_size=(N_train/N_total), random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL:\n",
    "N_eval = 100000\n",
    "data_eval = generate_data(random_seed + 99, k, N_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df66fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_limit_search = 1*60 # in seconds (time provided to search algorithm)\n",
    "time_limit_mosek = 10*60 # in seconds (for larger MIP / LP solves)\n",
    "time_limit_solve = 10*60 # in seconds (for individuals solves of SCP)\n",
    "max_nr_solutions = 1 # for easy problems with long time limits, we may want extra restriction\n",
    "add_remove_threshold = 0.00 # This determines when randomness is introduced in add/removal decision\n",
    "use_tabu = False # Determines whether the tabu list are used in the search\n",
    "\n",
    "add_strategy = 'random_vio'\n",
    "remove_strategy = 'random_any'\n",
    "clean_strategy = (999999, 'all_inactive') # set arbitrarily high such that it never occurs\n",
    "\n",
    "# Alters the Sampled Convex Problem\n",
    "solve_SCP = solve_SCP_SAA\n",
    "uncertain_constraint = uncertain_constraint_SAA\n",
    "\n",
    "(runtime, num_iter, solutions, \n",
    " best_sol, pareto_solutions) = rs.gen_and_eval_alg(data_train, data_test, beta, alpha, time_limit_search, time_limit_solve, \n",
    "                                                    max_nr_solutions, add_strategy, remove_strategy, clean_strategy, \n",
    "                                                    add_remove_threshold, use_tabu,\n",
    "                                                    phi_div, phi_dot, numeric_precision,\n",
    "                                                    solve_SCP, uncertain_constraint, check_robust,\n",
    "                                                    risk_measure, random_seed, \n",
    "                                                   num_obs_per_bin, data_eval, emp_eval_obj,\n",
    "                                                  analytic_out_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae78fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = best_sol['sol']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16355bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve SCP with many data points in set\n",
    "sol, obj = solve_SCP(k, data_eval, 10*60)\n",
    "x = sol\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25307f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e59938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio with equal weights\n",
    "x = np.array([None, None, None] + [1/k for i in range(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa0b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate obj emperically using data_eval\n",
    "emp_eval_obj(x, data_eval, rho, 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e0a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate obj analytically\n",
    "analytic_out_perf(x, rho, CVaR_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da0f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ddd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = x[3:]\n",
    "dataio.plot_single_portfolio_holdings(x_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac433bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataio.plot_pareto_curve(pareto_solutions, beta, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2466db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e019dd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db35a99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
