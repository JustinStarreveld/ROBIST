{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b1277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external packages\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import mosek\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# import internal packages\n",
    "import phi_divergence as phi\n",
    "from iter_gen_and_eval_alg import iter_gen_and_eval_alg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496bc27",
   "metadata": {},
   "source": [
    "The toy problem we examine is as follows:\n",
    "\n",
    "\\begin{align}\\label{toy_model_2}\n",
    "    \\begin{split}\n",
    "        \\max_{\\mathbf{0} \\leq \\mathbf{x} \\leq \\mathbf{10}}\\{\\mathbf{e}^T \\mathbf{x}: \\mathbf{\\xi}^T \\mathbf{x} \\leq 1,~\\sum_{j=1}^{k-1}x_j-x_k\\leq -1,~\\mathbf{x}\\leq 10\\}.\n",
    "    \\end{split}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "With $\\mathbf{x} \\in \\mathbb{R}^k$ and $\\mathbf{\\xi}\\in [-1,1]^{k}$ (assume uniformly distributed).\n",
    "\n",
    "We would like to obtain solutions for which we can make the following probabilistic guarantee regarding its feasibility: $$\\mathbb{P}^*(\\mathbf{\\xi}^T \\mathbf{x} \\leq 1)\\geq 1 - \\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external packages\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import math\n",
    "\n",
    "# import internal packages\n",
    "import phi_divergence as phi\n",
    "from iter_gen_and_eval_alg import iter_gen_and_eval_alg\n",
    "import util\n",
    "\n",
    "# problem specific functions:\n",
    "def generate_data(random_seed, N, **kwargs):\n",
    "    np.random.seed(random_seed)\n",
    "    dim_x = kwargs.get('dim_x',2)\n",
    "    data = np.random.uniform(-1,1,size = (N,dim_x)) # generates N random scenarios    \n",
    "    return data \n",
    "\n",
    "def generate_data_with_nominal(random_seed, N, **kwargs):\n",
    "    np.random.seed(random_seed)\n",
    "    dim_x = kwargs.get('dim_x',2)\n",
    "    data_nominal = np.array([[0] * dim_x])\n",
    "    data = np.random.uniform(-1,1,size = (N-1,dim_x)) # generate N-1 scenarios\n",
    "    data = np.concatenate((data_nominal,data)) # add nominal case to training data\n",
    "    return data\n",
    "\n",
    "def solve_P_SCP(S, **kwargs):\n",
    "    dim_x = kwargs.get('dim_x', 2)\n",
    "    x = cp.Variable(dim_x, nonneg = True)\n",
    "    setup_time_start = time.time()\n",
    "    constraints = [cp.sum(x[0:(dim_x-1)]) <= x[dim_x-1]-1, x<=10]\n",
    "    for s in range(len(S)):\n",
    "        constraints.append(cp.multiply(S[s], x) - 1 <= 0)\n",
    "    obj = cp.Minimize(- cp.sum(x)) # formulate as a minimization problem\n",
    "    prob = cp.Problem(obj,constraints)\n",
    "    time_limit = kwargs.get('time_limit', 2*60*60) - (time.time() - setup_time_start)\n",
    "    if time_limit < 0:\n",
    "        print(\"Error: did not provide sufficient time for setting up & solving problem\")\n",
    "        return (None, None)\n",
    "    try:\n",
    "#         prob.solve(solver=cp.MOSEK, mosek_params = {mosek.dparam.optimizer_max_time: time_limit})\n",
    "        prob.solve(solver=cp.GUROBI, verbose=False, TimeLimit=time_limit)\n",
    "    except cp.error.SolverError:\n",
    "        return (None, None)\n",
    "    return (x.value, prob.value)\n",
    "\n",
    "def unc_func(x, data, **kwargs):\n",
    "    return (np.dot(data,x)) - 1\n",
    "    \n",
    "def get_true_prob(x, dim_x):\n",
    "    return(1/2+1/(2*x[dim_x-1]))\n",
    "    \n",
    "def solve_toyproblem_true_prob(desired_rhs, dim_x):\n",
    "    beta = desired_rhs\n",
    "    x = cp.Variable(dim_x, nonneg = True)\n",
    "    constraints = [(1-2*beta)*x[dim_x-1] + 1 >= 0, cp.sum(x[0:(dim_x-1)]) <= x[dim_x-1]-1, x<=10]\n",
    "    obj = cp.Maximize(cp.sum(x))\n",
    "    prob = cp.Problem(obj,constraints)\n",
    "#     prob.solve(solver=cp.MOSEK)\n",
    "    prob.solve(solver=cp.GUROBI)\n",
    "    return(x.value, prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7addd891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phi_divergence import mod_chi2_cut\n",
    "import scipy.stats\n",
    "import itertools\n",
    "\n",
    "def solve_with_ihsan2013(dim_x,risk_param_epsilon,conf_param_alpha,data,m_j=10,\n",
    "                         omega_init=0.1,step_size=0.01,use_robist_lb=False):\n",
    "    def make_center(lb,ub,m_j):\n",
    "        delta = (ub-lb)/m_j\n",
    "        center = np.arange(lb+delta/2,ub,delta)\n",
    "        return(center)          \n",
    "\n",
    "    def get_freq(m_j,data,lb,ub):\n",
    "        Freq = np.zeros(m_j)\n",
    "        delta = (ub-lb)/m_j\n",
    "        for i in range(len(data)):\n",
    "            index = int(np.floor((data[i]-lb)/delta))\n",
    "            Freq[index] = Freq[index] + 1\n",
    "        return(Freq/len(data))\n",
    "    \n",
    "    def get_freq_v2(data,lb,ub,m_j,indices):\n",
    "        dim_x = len(data[0])\n",
    "        num_cells = len(indices)\n",
    "        Freq = np.zeros(num_cells)\n",
    "        delta = (ub-lb)/m_j\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            ind = 0\n",
    "            for j in range(dim_x):\n",
    "                index_j = int(np.floor((data[i][j]-lb)/delta))\n",
    "                ind += m_j**(dim_x - 1 - j) * index_j\n",
    "            Freq[ind] += 1\n",
    "        return(Freq/len(data))\n",
    "\n",
    "    def solve_rc(omega,a,b):\n",
    "        d = len(a[0])\n",
    "        x = cp.Variable(d, nonneg = True)\n",
    "        z = cp.Variable(d)\n",
    "        w = cp.Variable(d)\n",
    "        constraints = [cp.norm(z,1)+omega*cp.norm(w,2) + a[0] @ x <= b]\n",
    "        for i in range(d):\n",
    "            constraints.append(z[i] + w[i] == -a[i+1] @ x) \n",
    "        \n",
    "        # add our additional constraints\n",
    "        constraints.append(cp.sum(x[0:(d-1)]) <= x[d-1]-1)\n",
    "        constraints.append(x<=10)\n",
    "        \n",
    "        obj = cp.Maximize(cp.sum(x))\n",
    "        prob = cp.Problem(obj,constraints)\n",
    "        # prob.solve(solver = cp.MOSEK)\n",
    "        prob.solve(solver = cp.GUROBI)\n",
    "        return(x.value)\n",
    "\n",
    "    def lower_bound(alpha,p,S,N,phi_dot=2):\n",
    "        N_v = len(p)\n",
    "        q = cp.Variable(N_v, nonneg = True)\n",
    "        t = cp.Variable(N_v, nonneg = True)\n",
    "        r = phi_dot/(2*N)*scipy.stats.chi2.ppf(1-alpha, N_v-1)\n",
    "        constraints = [cp.sum(q) == 1]\n",
    "        f_obj = 0\n",
    "        for i in range(N_v):\n",
    "            if S[i] == 1:\n",
    "                f_obj = f_obj + q[i]\n",
    "            z = cp.vstack([2*(q[i]-p[i]),(t[i]-q[i])])\n",
    "            constraints.append(cp.norm(z,2) <= (t[i]+q[i]))\n",
    "        constraints.append(cp.sum(t) <= r)\n",
    "        obj = cp.Minimize(f_obj)\n",
    "        prob = cp.Problem(obj,constraints)\n",
    "        # prob.solve(solver = cp.MOSEK)\n",
    "        prob.solve(solver = cp.GUROBI)\n",
    "        return(prob.value)\n",
    "        \n",
    "    def cpt_feas(cpt_arr,x,a,b,indices):\n",
    "        d = len(cpt_arr)\n",
    "        S = np.zeros(len(indices))\n",
    "        for i in range(len(S)):\n",
    "            const = a[0]\n",
    "            for j in range(d):\n",
    "                const = const + cpt_arr[j][indices[i][j]] * a[j+1] \n",
    "            if const.dot(x) <= b:\n",
    "                S[i] = 1\n",
    "        return(S)\n",
    "    \n",
    "    def lower_bound_ROBIST(data, x, conf_param_alpha, phi_div=mod_chi2_cut, phi_dot=2, numeric_precision=1e-6):\n",
    "        N = len(data)\n",
    "        constr_evals = (np.dot(data,x)) - 1\n",
    "        N_vio = sum(constr_evals>(0+numeric_precision))\n",
    "        p_vio = N_vio/N\n",
    "        if p_vio == 0:\n",
    "            return 1\n",
    "        elif p_vio == 1:\n",
    "            return 0\n",
    "        return util.compute_cc_lb_chi2_analytic(1-p_vio, N, conf_param_alpha)\n",
    "    \n",
    "    def get_true_prob(x, dim_x):\n",
    "        return(1/2+1/(2*x[dim_x-1]))\n",
    "    \n",
    "    # see notation from ihsan2013\n",
    "    # a = [np.array([1,1]), np.array([1,0]), np.array([0,1])]\n",
    "    # b = 10\n",
    "    a = []\n",
    "    for i in range(dim_x+1):\n",
    "        if i == 0:\n",
    "            a.append(np.array([0 for j in range(dim_x)]))\n",
    "        else:\n",
    "            temp = [0 for j in range(i-1)]\n",
    "            temp.append(1)\n",
    "            temp = temp + [0 for j in range(i, dim_x)]\n",
    "            a.append(np.array(temp))\n",
    "    b = 1\n",
    "    \n",
    "    N = len(data)\n",
    "    \n",
    "    cpt_arr = []\n",
    "    lb = -1\n",
    "    ub = 1\n",
    "    m_j = m_j # assume that the support is always split into 10 equal intervals, even as dim_x increases\n",
    "    \n",
    "    # OLD CODE: Assumes independence\n",
    "    # np.random.seed(random_seed) \n",
    "    # xi = np.random.uniform(size = (dim_x,N))*2-1\n",
    "    # N = N**dim_x # assume data is indep and all combinations are taken\n",
    "    # # to get all possible combinations of independent data:\n",
    "    # data = np.array(np.meshgrid(*xi)).T.reshape(-1,dim_x)\n",
    "    # indices = np.asarray(list((itertools.product(np.arange(m_j), repeat = dim_x))))\n",
    "    # p = np.zeros(len(indices))\n",
    "    # freq_ct = []\n",
    "    # for i in range(dim_x):\n",
    "    #     cpt_arr.append(make_center(lb,ub,m_j))\n",
    "    #     freq_ct.append(get_freq(m_j, data.T[i],lb,ub))\n",
    "    # for j in range(len(indices)):\n",
    "    #     p[j] = 1\n",
    "    #     for k in range(dim_x):\n",
    "    #         p[j] = p[j] * freq_ct[k][indices[j][k]]\n",
    "    \n",
    "    for i in range(dim_x):\n",
    "        cpt_arr.append(make_center(lb,ub,m_j))\n",
    "        \n",
    "    indices = np.asarray(list((itertools.product(np.arange(m_j), repeat = dim_x))))\n",
    "    p = get_freq_v2(data,lb,ub,m_j,indices)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    omega = omega_init\n",
    "    lowerbound = -np.inf\n",
    "    lb_gap_ihsan2013 = []\n",
    "    lb_gap_robist = []\n",
    "    \n",
    "    while lowerbound < 1-risk_param_epsilon:\n",
    "        x = solve_rc(omega,a,b)\n",
    "        S = cpt_feas(cpt_arr,x,a,b,indices)\n",
    "        lb_ihsan2013 = lower_bound(conf_param_alpha,p,S,N)\n",
    "        lb_robist = lower_bound_ROBIST(data,x,conf_param_alpha)\n",
    "        \n",
    "        if use_robist_lb:\n",
    "            lowerbound = lb_robist\n",
    "        else:\n",
    "            lowerbound = lb_ihsan2013\n",
    "        \n",
    "        true_prob = get_true_prob(x, dim_x)\n",
    "        \n",
    "        lb_gap_ihsan2013.append(abs(true_prob - lb_ihsan2013)/true_prob)\n",
    "        lb_gap_robist.append(abs(true_prob - lb_robist)/true_prob)\n",
    "        \n",
    "        obj = np.sum(x)\n",
    "        # print('omega:', omega)\n",
    "        # print('True Prob:',get_true_prob(x, dim_x))\n",
    "        # print('lowerbound Ihsan:',lb_ihsan2013)\n",
    "        # print('lowerbound ROBIST:',lb_robist)\n",
    "        # print('Objective:', obj)\n",
    "        # print()\n",
    "        omega = omega + step_size\n",
    "    runtime = time.time() - start_time\n",
    "    avg_lb_gap_ihsan2013 = sum(lb_gap_ihsan2013) / len(lb_gap_ihsan2013)\n",
    "    avg_lb_gap_robist = sum(lb_gap_robist) / len(lb_gap_robist)\n",
    "    return runtime, x, obj, lb_ihsan2013, avg_lb_gap_ihsan2013, avg_lb_gap_robist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a8b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter values\n",
    "dim_x = 2\n",
    "problem_instance = {'dim_x': dim_x, 'time_limit': 10*60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c73db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and split data into train and test\n",
    "random_seed = 0\n",
    "N_total = 10000\n",
    "data = generate_data(random_seed, N_total, dim_x=dim_x)\n",
    "\n",
    "N_train = N_total / 2\n",
    "data_train, data_test = train_test_split(data, train_size=(N_train/N_total), random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b18899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our own algorithm parameter values\n",
    "risk_param_epsilon = 0.10\n",
    "conf_param_alpha = 0.05\n",
    "add_strategy = 'random_vio'\n",
    "remove_strategy = 'random_any'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f978590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide functions and other info for generating & evaluating solutions\n",
    "solve_SCP = solve_P_SCP\n",
    "eval_unc_obj = None\n",
    "eval_unc_constr = [{'function': unc_func,\n",
    "                    'info': {'risk_measure': 'probability', # must be either 'probability' or 'expectation'\n",
    "                             'desired_rhs': 1 - risk_param_epsilon}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the algorithm\n",
    "alg = iter_gen_and_eval_alg(solve_SCP, problem_instance, eval_unc_obj, eval_unc_constr, \n",
    "                            data_train, data_test, conf_param_alpha=conf_param_alpha,\n",
    "                            add_strategy=add_strategy ,remove_strategy=remove_strategy,\n",
    "                            verbose=True)\n",
    "\n",
    "stop_criteria={'max_elapsed_time': 0.5*60} # in seconds (time provided to search algorithm)\n",
    "\n",
    "(best_sol, runtime, num_iter, pareto_frontier, S_history) = alg.run(stop_criteria=stop_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f034ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3db6d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429175a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fc02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL:\n",
    "N_eval = 50000\n",
    "data_eval = generate_data(random_seed + 99, N_eval, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e87b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = problem_info['desired_prob_guarantee_beta']\n",
    "x_true, obj_true = solve_toyproblem_true_prob(beta, k)\n",
    "obj_alg = best_sol['obj']\n",
    "obj_gap_true =  100*(obj_true - obj_alg)/obj_true\n",
    "obj_gap_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b5fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal solution given data_test\n",
    "runtime, opt_x, opt_sum_y, opt_obj, opt_lb = util.compute_opt_given_data(conf_param_alpha, beta, phi_div, phi_dot, data_test)\n",
    "obj_alg = best_sol['obj']\n",
    "obj_gap_opt = 100*(opt_obj - obj_alg)/opt_obj\n",
    "obj_gap_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1c912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,sol in enumerate(solutions):\n",
    "    if i<=7:\n",
    "        Z_arr = data_train[sol['scenario_set']]\n",
    "        true_prob = get_true_prob(sol['sol'], k)\n",
    "        if i == 0:\n",
    "            dataio.plot_iter(i, data_train, Z_arr, sol['sol'], sol['obj'], \n",
    "                             sol['p_train'], sol['lb_train'], true_prob,\n",
    "                             True, \"png\", True, N_train, alpha, beta)\n",
    "        else:\n",
    "            dataio.plot_iter(i, data_train, Z_arr, sol['sol'], sol['obj'], \n",
    "                             sol['p_train'], sol['lb_train'], true_prob,\n",
    "                             True, \"png\", False, N_train, alpha, beta)\n",
    "        \n",
    "            dataio.plot_iter(i, data_test, None, sol['sol'], sol['obj'], \n",
    "                             sol['p_test'], sol['lb_test'], true_prob,\n",
    "                             True, \"png\", False, N_test, alpha, beta)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287d75d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataio.plot_pareto_curve(pareto_solutions, beta, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86a966",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataio.plot_obj_over_time(solutions, best_sol, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9e83c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataio.plot_size_set_over_time(solutions, best_sol, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc263207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3502e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final solution found by algorithm\n",
    "name = 'Strategy: '+ str(add_strategy)\n",
    "save_plot = False\n",
    "plot_type = \"eps\"\n",
    "show_legend = True\n",
    "Z_values = data_train[best_sol['scenario_set']]\n",
    "dataio.plot_solution(name, data_train, Z_values, best_sol['sol'], \n",
    "              best_sol['obj'], best_sol['lb_test'], save_plot, plot_type, show_legend, N, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db1778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute optimal solution with true probability constraint\n",
    "prob_true = beta\n",
    "[x_true, obj_true] = solve_toyproblem_true_prob(prob_true, k)\n",
    "constr = uncertain_constraint(data_test, x_true)\n",
    "vio = constr[constr>(0+numeric_precision)]   \n",
    "p_vio = len(vio)/N_train\n",
    "p = np.array([1-p_vio, p_vio])\n",
    "r = phi_dot/(2*N_test)*scipy.stats.chi2.ppf(1-alpha, 1)\n",
    "lb = rs.compute_lb(p, r, par, phi_div)\n",
    "print(p)\n",
    "print(lb)\n",
    "print(obj_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3dbb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"TrueProb=\"+str(prob_true)\n",
    "save_plot = False\n",
    "plot_type = \"eps\"\n",
    "show_legend = True\n",
    "dataio.plot_solution(name, data_test, None, x_true, obj_true, lb, save_plot, plot_type, show_legend, N, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal solution given data_test\n",
    "runtime, opt_x, opt_sum_y, opt_obj, opt_lb = util.compute_opt_given_data(alpha, beta, par, phi_div, data_test, time_limit_mosek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4134aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea770992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optimal solution given data_test\n",
    "name = 'Opt_given_test_data'\n",
    "save_plot = False\n",
    "plot_type = \"eps\"\n",
    "show_legend = True\n",
    "dataio.plot_solution(name, data_test, None, opt_x, opt_obj, opt_lb, save_plot, plot_type, show_legend, N, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ddec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute solution via Campi method\n",
    "data = generate_data(k, N_campi)\n",
    "runtime, campi_x, campi_obj, campi_true_prob, Z_arr = util.solve_with_campi_N(alpha, beta, numeric_precision, data, time_limit_mosek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Campi solution\n",
    "name = 'Campi method'\n",
    "save_plot = False\n",
    "plot_type = \"eps\"\n",
    "show_legend = True\n",
    "dataio.plot_solution(name, data, Z_arr, campi_x, campi_obj, 0, save_plot, plot_type, show_legend, N, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58becfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00682b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Garatti2022 solution\n",
    "k = 1000\n",
    "dim_x = k\n",
    "beta = 0.95\n",
    "alpha = 10e-6\n",
    "time_limit_solve = 5*60\n",
    "numeric_precision = 1e-6\n",
    "\n",
    "set_sizes, time_determine_set_sizes = util.Garatti2022_determine_set_sizes(dim_x, beta, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Calafiore2016 solution\n",
    "k = 10\n",
    "dim_x = k\n",
    "beta = 0.95\n",
    "alpha = 10e-6\n",
    "time_limit_solve = 5*60\n",
    "numeric_precision = 1e-6\n",
    "\n",
    "scale_eps_prime = 0.7\n",
    "N_eval = 10000\n",
    "\n",
    "N, time_determine_set_sizes = util.determine_N_calafiore2016(dim_x, beta, alpha, scale_eps_prime, N_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419c0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1433f0c8",
   "metadata": {},
   "source": [
    "# Numerical Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f27e396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_file_name = 'tp_ihsan2013_k=3_mj=10_eps=0.05_alpha=0.01_seeds=1-10'\n",
    "\n",
    "headers = ['seed', '$k$', '$m_j$', '$m$', '$N_{min}$', \n",
    "           'N', '$N_1$', '$N_2$', '$T$ (ishan2013)', '$T$ (ROBIST)', \n",
    "           'obj. (ishan2013)', 'obj. (ROBIST)', 'opt. obj. (true)',\n",
    "           '$\\gamma$ (ishan2013)', '$\\gamma$ (ROBIST)', \n",
    "           'true prob. (ishan2013)', 'true prob. (ROBIST)',\n",
    "           'prob. MAPE (ishan2013)', 'prob. MAPE (ROBIST)',\n",
    "           '\\#Iter.~(\\\\texttt{add})', '\\#Iter.~(\\\\texttt{remove})', \n",
    "           '$\\mu_{|\\mathcal{S}_i|}$', '$\\max_{i}|\\mathcal{S}_i|$']\n",
    "\n",
    "# Write headers to .txt file\n",
    "with open(r'output/ToyProblem/headers_'+output_file_name+'.txt','w+') as f:\n",
    "    f.write(str(headers))\n",
    "\n",
    "output_data = {}\n",
    "\n",
    "# set parameter values\n",
    "risk_param_epsilon = 0.05\n",
    "conf_param_alpha = 0.01\n",
    "dim_x = 3\n",
    "m_j = 10\n",
    "m = m_j**dim_x\n",
    "N_min = 5*m\n",
    "N = 2*N_min\n",
    "\n",
    "N_train = math.floor(N/2)\n",
    "N_test = N - N_train\n",
    "# str_tmp = \"(\"+str(N_train)+\", \"+str(N_test)+\")\"\n",
    "# print(dim_x, m_j, m, N_min, N, str_tmp)\n",
    "\n",
    "opt_x_true, opt_obj_true = solve_toyproblem_true_prob(1-risk_param_epsilon, dim_x)\n",
    "\n",
    "problem_instance = {}\n",
    "problem_instance['dim_x'] = dim_x\n",
    "problem_instance['time_limit'] = 1*60*60 \n",
    "\n",
    "# ROBIST settings:\n",
    "stop_criteria={'max_elapsed_time': 1*60} \n",
    "solve_SCP = solve_P_SCP\n",
    "eval_unc_obj = None\n",
    "eval_unc_constr = [{'function': unc_func,\n",
    "                   'info': {'risk_measure': 'probability', # must be either 'probability' or 'expectation'\n",
    "                            'desired_rhs': 1 - risk_param_epsilon}}]\n",
    "\n",
    "random_seed_settings = [i for i in range(1,11)] #101\n",
    "run_count = 0\n",
    "for random_seed in random_seed_settings:\n",
    "    \n",
    "    data = generate_data(random_seed, N, dim_x=dim_x)               \n",
    "    data_train, data_test = train_test_split(data, train_size=(N_train/N), random_state=random_seed)\n",
    "\n",
    "    # ihsan2013:\n",
    "    runtime_ihsan2013, x, obj_ihsan2013, lb_ihsan2013, avg_lb_gap_ihsan2013, avg_lb_gap_robist = solve_with_ihsan2013(dim_x,risk_param_epsilon,conf_param_alpha,data,m_j=m_j,\n",
    "                                                                                                                      Omega_init=0.0,step_size=0.01,random_seed=random_seed)\n",
    "    true_prob_ihsan2013 = get_true_prob(x, dim_x)\n",
    "\n",
    "    # ROBIST:\n",
    "    alg = iter_gen_and_eval_alg(solve_SCP, problem_instance, eval_unc_obj, eval_unc_constr, \n",
    "                                data_train, data_test, conf_param_alpha=conf_param_alpha,\n",
    "                                verbose=False)\n",
    "    \n",
    "    (best_sol, runtime_alg, num_iter, pareto_frontier, S_history) = alg.run(stop_criteria=stop_criteria)\n",
    "    \n",
    "    lb_alg = best_sol['feas'][0]\n",
    "    obj_alg = - best_sol['obj']\n",
    "    true_prob_alg = get_true_prob(best_sol['sol'], dim_x)\n",
    "    S_avg = sum(len(S_i) for S_i in S_history) / len(S_history)\n",
    "    S_max = max(len(S_i) for S_i in S_history)\n",
    "    num_iter_add = num_iter['add']\n",
    "    num_iter_remove = num_iter['remove']\n",
    "    \n",
    "    # # turn off:   \n",
    "    # (best_sol, runtime_alg, num_iter, pareto_frontier, S_history) = (np.nan, np.nan, np.nan, np.nan, np.nan)\n",
    "    # lb_alg = np.nan\n",
    "    # obj_alg = np.nan\n",
    "    # true_prob_alg = np.nan\n",
    "    # S_avg = np.nan\n",
    "    # S_max = np.nan\n",
    "    # num_iter_add = np.nan\n",
    "    # num_iter_remove = np.nan\n",
    "\n",
    "    output_data[(random_seed, dim_x, m_j)] = [m_j, m, N_min, N, N_train, N_test, \n",
    "                                              runtime_ihsan2013, runtime_alg, \n",
    "                                              obj_ihsan2013, obj_alg, opt_obj_true,\n",
    "                                              lb_ihsan2013, lb_alg,\n",
    "                                              true_prob_ihsan2013, true_prob_alg,\n",
    "                                              avg_lb_gap_ihsan2013, avg_lb_gap_robist,\n",
    "                                              num_iter_add, num_iter_remove,\n",
    "                                              S_avg, S_max]\n",
    "    \n",
    "    output_file_name = 'new_output_data'\n",
    "    with open(r'output/ToyProblem/'+output_file_name+'.txt','w+') as f:\n",
    "        f.write(str(output_data))\n",
    "    \n",
    "    run_count += 1\n",
    "    print(\"Completed run: \" + str(run_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "decf2df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run: 1\n",
      "Completed run: 2\n",
      "Completed run: 3\n",
      "Completed run: 4\n",
      "Completed run: 5\n",
      "Completed run: 6\n",
      "Completed run: 7\n",
      "Completed run: 8\n",
      "Completed run: 9\n",
      "Completed run: 10\n"
     ]
    }
   ],
   "source": [
    "output_file_name = 'tp_ihsan2013_k=5_mj=10_eps=0.05_alpha=0.01_seeds=1-10'\n",
    "\n",
    "headers = ['seed', '$k$', '$m_j$', '$m$', '$N_{min}$', \n",
    "           'N', '$N_1$', '$N_2$', '$T$ (ishan2013)', '$T$ (ROBIST)', \n",
    "           'obj. (ishan2013)', 'obj. (ROBIST)', 'opt. obj. (true)',\n",
    "           '$\\gamma$ (ishan2013)', '$\\gamma$ (ROBIST)', \n",
    "           'true prob. (ishan2013)', 'true prob. (ROBIST)',\n",
    "           'prob. MAPE (ishan2013)', 'prob. MAPE (ROBIST)',\n",
    "           '\\#Iter.~(\\\\texttt{add})', '\\#Iter.~(\\\\texttt{remove})', \n",
    "           '$\\mu_{|\\mathcal{S}_i|}$', '$\\max_{i}|\\mathcal{S}_i|$']\n",
    "\n",
    "# Write headers to .txt file\n",
    "with open(r'output/ToyProblem/headers_'+output_file_name+'.txt','w+') as f:\n",
    "    f.write(str(headers))\n",
    "\n",
    "output_data = {}\n",
    "\n",
    "# set parameter values\n",
    "risk_param_epsilon = 0.05\n",
    "conf_param_alpha = 0.01\n",
    "dim_x = 5\n",
    "m_j = 10\n",
    "m = m_j**dim_x\n",
    "N_min = 5*m\n",
    "N = 2*N_min\n",
    "\n",
    "N_train = math.floor(N/2)\n",
    "N_test = N - N_train\n",
    "# str_tmp = \"(\"+str(N_train)+\", \"+str(N_test)+\")\"\n",
    "# print(dim_x, m_j, m, N_min, N, str_tmp)\n",
    "\n",
    "opt_x_true, opt_obj_true = solve_toyproblem_true_prob(1-risk_param_epsilon, dim_x)\n",
    "\n",
    "problem_instance = {}\n",
    "problem_instance['dim_x'] = dim_x\n",
    "problem_instance['time_limit'] = 1*60*60 \n",
    "\n",
    "# ROBIST settings:\n",
    "stop_criteria={'max_elapsed_time': 1*60} \n",
    "solve_SCP = solve_P_SCP\n",
    "eval_unc_obj = None\n",
    "eval_unc_constr = [{'function': unc_func,\n",
    "                   'info': {'risk_measure': 'probability', # must be either 'probability' or 'expectation'\n",
    "                            'desired_rhs': 1 - risk_param_epsilon}}]\n",
    "\n",
    "random_seed_settings = [i for i in range(1,11)] #101\n",
    "run_count = 0\n",
    "for random_seed in random_seed_settings:\n",
    "    \n",
    "    data = generate_data(random_seed, N, dim_x=dim_x)               \n",
    "    data_train, data_test = train_test_split(data, train_size=(N_train/N), random_state=random_seed)\n",
    "\n",
    "    # ihsan2013:\n",
    "#     runtime_ihsan2013, x, obj_ihsan2013, lb_ihsan2013, avg_lb_gap_ihsan2013, avg_lb_gap_robist = solve_with_ihsan2013(dim_x,risk_param_epsilon,conf_param_alpha,data,m_j=m_j,\n",
    "#                                                                                                                       Omega_init=0.0,step_size=0.01,random_seed=random_seed)\n",
    "#     true_prob_ihsan2013 = get_true_prob(x, dim_x)\n",
    "\n",
    "    # turn off:\n",
    "    runtime_ihsan2013 = np.nan\n",
    "    obj_ihsan2013 = np.nan\n",
    "    lb_ihsan2013 = np.nan\n",
    "    avg_lb_gap_ihsan2013 = np.nan\n",
    "    avg_lb_gap_robist = np.nan\n",
    "    true_prob_ihsan2013 = np.nan\n",
    "\n",
    "    # ROBIST:\n",
    "    alg = iter_gen_and_eval_alg(solve_SCP, problem_instance, eval_unc_obj, eval_unc_constr, \n",
    "                                data_train, data_test, conf_param_alpha=conf_param_alpha,\n",
    "                                verbose=False)\n",
    "    \n",
    "    (best_sol, runtime_alg, num_iter, pareto_frontier, S_history) = alg.run(stop_criteria=stop_criteria)\n",
    "    \n",
    "    lb_alg = best_sol['feas'][0]\n",
    "    obj_alg = - best_sol['obj']\n",
    "    true_prob_alg = get_true_prob(best_sol['sol'], dim_x)\n",
    "    S_avg = sum(len(S_i) for S_i in S_history) / len(S_history)\n",
    "    S_max = max(len(S_i) for S_i in S_history)\n",
    "    num_iter_add = num_iter['add']\n",
    "    num_iter_remove = num_iter['remove']\n",
    "    \n",
    "    # # turn off:   \n",
    "    # (best_sol, runtime_alg, num_iter, pareto_frontier, S_history) = (np.nan, np.nan, np.nan, np.nan, np.nan)\n",
    "    # lb_alg = np.nan\n",
    "    # obj_alg = np.nan\n",
    "    # true_prob_alg = np.nan\n",
    "    # S_avg = np.nan\n",
    "    # S_max = np.nan\n",
    "    # num_iter_add = np.nan\n",
    "    # num_iter_remove = np.nan\n",
    "\n",
    "    output_data[(random_seed, dim_x, m_j)] = [m_j, m, N_min, N, N_train, N_test, \n",
    "                                              runtime_ihsan2013, runtime_alg, \n",
    "                                              obj_ihsan2013, obj_alg, opt_obj_true,\n",
    "                                              lb_ihsan2013, lb_alg,\n",
    "                                              true_prob_ihsan2013, true_prob_alg,\n",
    "                                              avg_lb_gap_ihsan2013, avg_lb_gap_robist,\n",
    "                                              num_iter_add, num_iter_remove,\n",
    "                                              S_avg, S_max]\n",
    "    \n",
    "    output_file_name = 'new_output_data_2'\n",
    "    with open(r'output/ToyProblem/'+output_file_name+'.txt','w+') as f:\n",
    "        f.write(str(output_data))\n",
    "    \n",
    "    run_count += 1\n",
    "    print(\"Completed run: \" + str(run_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cbb93dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.365718126297,\n",
       "  nan,\n",
       "  1.2055159426503064,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9526946574297765,\n",
       "  nan,\n",
       "  0.9534086472294225,\n",
       "  nan,\n",
       "  nan,\n",
       "  80,\n",
       "  78,\n",
       "  2.867088607594937,\n",
       "  8],\n",
       " (2, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.13407039642334,\n",
       "  nan,\n",
       "  1.1848663110687707,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9568579127506267,\n",
       "  nan,\n",
       "  0.9576939078303743,\n",
       "  nan,\n",
       "  nan,\n",
       "  80,\n",
       "  78,\n",
       "  2.7151898734177213,\n",
       "  7],\n",
       " (3, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.185465574264526,\n",
       "  nan,\n",
       "  1.2119132843865374,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9508121760515322,\n",
       "  nan,\n",
       "  0.9520972892829046,\n",
       "  nan,\n",
       "  nan,\n",
       "  93,\n",
       "  92,\n",
       "  2.9783783783783786,\n",
       "  8],\n",
       " (4, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.12677764892578,\n",
       "  nan,\n",
       "  1.2070594954042226,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9518621549221422,\n",
       "  nan,\n",
       "  0.9530915465044363,\n",
       "  nan,\n",
       "  nan,\n",
       "  138,\n",
       "  135,\n",
       "  2.9853479853479854,\n",
       "  8],\n",
       " (5, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.002524852752686,\n",
       "  nan,\n",
       "  1.2186596754084724,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9504332946318473,\n",
       "  nan,\n",
       "  0.950722574121645,\n",
       "  nan,\n",
       "  nan,\n",
       "  135,\n",
       "  134,\n",
       "  2.8141263940520447,\n",
       "  8],\n",
       " (6, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.030322551727295,\n",
       "  nan,\n",
       "  1.2173130153480036,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9502337858289523,\n",
       "  nan,\n",
       "  0.9509963153953036,\n",
       "  nan,\n",
       "  nan,\n",
       "  132,\n",
       "  131,\n",
       "  3.0342205323193916,\n",
       "  8],\n",
       " (7, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.166022062301636,\n",
       "  nan,\n",
       "  1.2164543227067925,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.950161237712965,\n",
       "  nan,\n",
       "  0.9511710391481353,\n",
       "  nan,\n",
       "  nan,\n",
       "  133,\n",
       "  131,\n",
       "  2.9242424242424243,\n",
       "  10],\n",
       " (8, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.25354814529419,\n",
       "  nan,\n",
       "  1.2138008968575167,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.950656993223978,\n",
       "  nan,\n",
       "  0.9517118054381029,\n",
       "  nan,\n",
       "  nan,\n",
       "  128,\n",
       "  127,\n",
       "  2.831372549019608,\n",
       "  9],\n",
       " (9, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.10335922241211,\n",
       "  nan,\n",
       "  1.207879019058939,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9526765163081579,\n",
       "  nan,\n",
       "  0.9529233673438451,\n",
       "  nan,\n",
       "  nan,\n",
       "  131,\n",
       "  128,\n",
       "  2.7567567567567566,\n",
       "  8],\n",
       " (10, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.08528804779053,\n",
       "  nan,\n",
       "  1.215678217733887,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9502619987597847,\n",
       "  nan,\n",
       "  0.9513290747709577,\n",
       "  nan,\n",
       "  nan,\n",
       "  129,\n",
       "  130,\n",
       "  2.555984555984556,\n",
       "  6]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import nan\n",
    "\n",
    "output_file_name = 'tp_ihsan2013_k=5_mj=10_eps=0.05_alpha=0.01_seeds=1-10'\n",
    "# Read from .txt file\n",
    "file_path = 'output/ToyProblem/'+output_file_name+'.txt'\n",
    "dic = ''\n",
    "with open(file_path,'r') as f:\n",
    "     for i in f.readlines():\n",
    "        if i != \"nan\":\n",
    "            dic=i #string\n",
    "output_data_read = eval(dic)\n",
    "output_data_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f77c0121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.365718126297,\n",
       "  nan,\n",
       "  1.2055159426503064,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9526946574297765,\n",
       "  nan,\n",
       "  0.9534086472294225,\n",
       "  nan,\n",
       "  nan,\n",
       "  80,\n",
       "  78,\n",
       "  2.867088607594937,\n",
       "  8],\n",
       " (2, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.13407039642334,\n",
       "  nan,\n",
       "  1.1848663110687707,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9568579127506267,\n",
       "  nan,\n",
       "  0.9576939078303743,\n",
       "  nan,\n",
       "  nan,\n",
       "  80,\n",
       "  78,\n",
       "  2.7151898734177213,\n",
       "  7],\n",
       " (3, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.185465574264526,\n",
       "  nan,\n",
       "  1.2119132843865374,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9508121760515322,\n",
       "  nan,\n",
       "  0.9520972892829046,\n",
       "  nan,\n",
       "  nan,\n",
       "  93,\n",
       "  92,\n",
       "  2.9783783783783786,\n",
       "  8],\n",
       " (4, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.12677764892578,\n",
       "  nan,\n",
       "  1.2070594954042226,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9518621549221422,\n",
       "  nan,\n",
       "  0.9530915465044363,\n",
       "  nan,\n",
       "  nan,\n",
       "  138,\n",
       "  135,\n",
       "  2.9853479853479854,\n",
       "  8],\n",
       " (5, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.002524852752686,\n",
       "  nan,\n",
       "  1.2186596754084724,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9504332946318473,\n",
       "  nan,\n",
       "  0.950722574121645,\n",
       "  nan,\n",
       "  nan,\n",
       "  135,\n",
       "  134,\n",
       "  2.8141263940520447,\n",
       "  8],\n",
       " (6, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.030322551727295,\n",
       "  nan,\n",
       "  1.2173130153480036,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9502337858289523,\n",
       "  nan,\n",
       "  0.9509963153953036,\n",
       "  nan,\n",
       "  nan,\n",
       "  132,\n",
       "  131,\n",
       "  3.0342205323193916,\n",
       "  8],\n",
       " (7, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.166022062301636,\n",
       "  nan,\n",
       "  1.2164543227067925,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.950161237712965,\n",
       "  nan,\n",
       "  0.9511710391481353,\n",
       "  nan,\n",
       "  nan,\n",
       "  133,\n",
       "  131,\n",
       "  2.9242424242424243,\n",
       "  10],\n",
       " (8, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.25354814529419,\n",
       "  nan,\n",
       "  1.2138008968575167,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.950656993223978,\n",
       "  nan,\n",
       "  0.9517118054381029,\n",
       "  nan,\n",
       "  nan,\n",
       "  128,\n",
       "  127,\n",
       "  2.831372549019608,\n",
       "  9],\n",
       " (9, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.10335922241211,\n",
       "  nan,\n",
       "  1.207879019058939,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9526765163081579,\n",
       "  nan,\n",
       "  0.9529233673438451,\n",
       "  nan,\n",
       "  nan,\n",
       "  131,\n",
       "  128,\n",
       "  2.7567567567567566,\n",
       "  8],\n",
       " (10, 5, 10): [10,\n",
       "  100000,\n",
       "  500000,\n",
       "  1000000,\n",
       "  500000,\n",
       "  500000,\n",
       "  nan,\n",
       "  60.08528804779053,\n",
       "  nan,\n",
       "  1.215678217733887,\n",
       "  1.2222222222222223,\n",
       "  nan,\n",
       "  0.9502619987597847,\n",
       "  nan,\n",
       "  0.9513290747709577,\n",
       "  nan,\n",
       "  nan,\n",
       "  129,\n",
       "  130,\n",
       "  2.555984555984556,\n",
       "  6]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data = output_data_read\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73b04184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          10.000000\n",
       "1      100000.000000\n",
       "2      500000.000000\n",
       "3     1000000.000000\n",
       "4      500000.000000\n",
       "5      500000.000000\n",
       "6                NaN\n",
       "7          60.145310\n",
       "8                NaN\n",
       "9           1.209914\n",
       "10          1.222222\n",
       "11               NaN\n",
       "12          0.951665\n",
       "13               NaN\n",
       "14          0.952515\n",
       "15               NaN\n",
       "16               NaN\n",
       "17        117.900000\n",
       "18        116.400000\n",
       "19          2.846271\n",
       "20          8.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain average and std dev\n",
    "import pandas as pd\n",
    "df_output = pd.DataFrame.from_dict(output_data, orient='index')\n",
    "df_output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf84fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_str = {}\n",
    "for i,res in output_data.items():\n",
    "    res_str = []\n",
    "    for i2,el in enumerate(res):\n",
    "        if i2 < 5:\n",
    "            if np.isnan(el):\n",
    "                res_str.append('-')\n",
    "            else:\n",
    "                res_str.append(f'{round(el,2):.2f}') \n",
    "        elif i2 == 5:\n",
    "            res_str.append(f'{round(el,0):.0f}') \n",
    "        else:\n",
    "            res_str.append(el)\n",
    "    \n",
    "    output_data_str[i] = res_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e646b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['$k$', 'seed', 'remove strategy', '$n_{\\mathcal{X}}$',\n",
    "           'Obj.~(RS)', 'Obj.~(TP)', 'Gap TP.~(\\%)', \n",
    "           'Obj.~($\\mathcal{D}^{\\\\text{test}}_{N_2}$)', 'Gap $\\mathcal{D}^{\\\\text{test}}_{N_2}$ (\\%)',\n",
    "           'Time', '$|\\mathcal{X}|$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataio.write_output_to_latex(4, headers, output_data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'new_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write headers + output to .txt file\n",
    "with open(r'output/headers_'+output_file_name+'.txt','w+') as f:\n",
    "    f.write(str(headers))\n",
    "\n",
    "# with open(r'output/'+output_file_name+'.txt','w+') as f:\n",
    "#     f.write(str(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3a33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e66771",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'eval_gap_as_L_to_inf_k=[2,10]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e164f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read from .txt file\n",
    "file_path = 'output/'+output_file_name+'.txt'\n",
    "dic = ''\n",
    "with open(file_path,'r') as f:\n",
    "         for i in f.readlines():\n",
    "            dic=i #string\n",
    "output_data_read = eval(dic)\n",
    "output_data_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239c73f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_data = output_data_read\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f52d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from .txt file\n",
    "file_path = 'output/headers_'+output_file_name+'.txt'\n",
    "dic = ''\n",
    "with open(file_path,'r') as f:\n",
    "         for i in f.readlines():\n",
    "            dic=i #string\n",
    "output_data_headers_read = eval(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc1ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = output_data_headers_read\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df061a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataio.write_output_to_latex(3, headers, output_data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de736569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "k = 1000\n",
    "beta = 0.9\n",
    "N_total_settings = [100]\n",
    "p_train_settings = [0.25, 0.5, 0.75]\n",
    "random_seed_data_settings = [i for i in range(1, 7)]\n",
    "random_seed_split_settings = [i for i in range(1, 11)]\n",
    "\n",
    "output_data_agg = {}\n",
    "for N_total in N_total_settings:\n",
    "    for p_train in p_train_settings:\n",
    "        \n",
    "        N_train = round(p_train * N_total)\n",
    "        N_test = N_total - N_train\n",
    "        \n",
    "        df = pd.DataFrame({key: pd.Series(val) for key, val in output_data.items() if (key[0] == N_train\n",
    "                                                                                       and key[1] == N_test\n",
    "                                                                                       and key[2] in random_seed_data_settings)})\n",
    "        df = df.astype(float)\n",
    "        df_agg = df.agg([\"mean\",\"std\"], axis=\"columns\")\n",
    "\n",
    "        df_feas = df.loc[:,df.iloc[3,:] >= beta]\n",
    "        df_feas_agg = df_feas.agg([\"mean\",\"std\"], axis=\"columns\")\n",
    "\n",
    "        prob_FF = sum(df.iloc[3,:] >= beta) / len(df.columns)\n",
    "        true_prob_FF = sum(df.iloc[4,:] >= beta) / len(df.columns)\n",
    "\n",
    "        avg_obj = df_agg.loc[0,'mean']\n",
    "        std_obj = df_agg.loc[0,'std']\n",
    "\n",
    "        if prob_FF > 0:\n",
    "            avg_obj_F = df_feas_agg.loc[0, 'mean']\n",
    "            std_obj_F = df_feas_agg.loc[0, 'std']\n",
    "            avg_gap_F = df_feas_agg.loc[1, 'mean']\n",
    "            std_gap_F = df_feas_agg.loc[1, 'std']\n",
    "        else:\n",
    "            avg_obj_F = 0\n",
    "            std_obj_F = 0\n",
    "            avg_gap_F = 0\n",
    "            std_gap_F = 0\n",
    "\n",
    "        avg_lb_train = df_agg.loc[2,'mean']\n",
    "        std_lb_train = df_agg.loc[2,'std']\n",
    "        avg_lb_test = df_agg.loc[3,'mean']\n",
    "        std_lb_test = df_agg.loc[3,'std']\n",
    "        avg_true_prob = df_agg.loc[4,'mean']\n",
    "        std_true_prob = df_agg.loc[4,'std']\n",
    "        \n",
    "        avg_num_test_feas_found = df_agg.loc[6,'mean']\n",
    "        std_num_test_feas_found = df_agg.loc[6,'std']\n",
    "        \n",
    "        avg_time_spent = df_agg.loc[8,'mean']\n",
    "        std_time_spent = df_agg.loc[8,'std']\n",
    "\n",
    "        li = []\n",
    "        li.append(f'{prob_FF:.2f}')\n",
    "        li.append(f'{true_prob_FF:.2f}')\n",
    "        #li.append(f'{round(avg_obj,3):.3f}' + \" (\"+f'{round(std_obj,3):.3f}'+\")\")\n",
    "        if prob_FF > 0:\n",
    "            li.append(f'{round(avg_obj_F,3):.3f}' + \" (\"+f'{round(std_obj_F,3):.3f}'+\")\")\n",
    "            li.append(f'{round(avg_gap_F,3):.3f}' + \" (\"+f'{round(std_gap_F,3):.3f}'+\")\")\n",
    "        else:\n",
    "            li.append(\"-\")\n",
    "            li.append(\"-\")\n",
    "        li.append(f'{round(avg_lb_train,3):.3f}' + \" (\"+f'{round(std_lb_train,3):.3f}'+\")\")\n",
    "        li.append(f'{round(avg_lb_test,3):.3f}' + \" (\"+f'{round(std_lb_test,3):.3f}'+\")\")\n",
    "        li.append(f'{round(avg_true_prob,3):.3f}' + \" (\"+f'{round(std_true_prob,3):.3f}'+\")\")\n",
    "        li.append(f'{round(avg_num_test_feas_found,1):.1f}' + \" (\"+f'{round(std_num_test_feas_found,1):.1f}'+\")\")\n",
    "        li.append(f'{round(avg_time_spent,1):.1f}' + \" (\"+f'{round(std_time_spent,1):.1f}'+\")\")\n",
    "\n",
    "        output_data_agg[(N_train, N_test, 'Single Split Run')] = li\n",
    "        \n",
    "        \n",
    "        count_FF = 0\n",
    "        count_true_FF = 0\n",
    "        best_obj = []\n",
    "        best_gap = []\n",
    "        lb_train = []\n",
    "        lb_test = []\n",
    "        true_prob = []\n",
    "        num_test_feas_found = []\n",
    "        time_spent = []\n",
    "        \n",
    "        for random_seed_data in random_seed_data_settings:\n",
    "            df = pd.DataFrame({key: pd.Series(val) for key, val in output_data.items() if (key[0] == N_train\n",
    "                                                                                       and key[1] == N_test\n",
    "                                                                                       and key[2] == random_seed_data)})\n",
    "            \n",
    "            if sum(df.iloc[3,:] >= beta) > 0:\n",
    "                count_FF += 1\n",
    "            if sum(df.iloc[4,:] >= beta) > 0:\n",
    "                count_true_FF += 1\n",
    "                \n",
    "            df_feas = df.loc[:,df.iloc[3,:] >= beta]\n",
    "            #df_feas_agg = df_feas.agg([\"mean\",\"std\",\"max\", \"min\"], axis=\"columns\")\n",
    "            if not df_feas.empty:\n",
    "                best_i = df_feas.idxmax(axis=1)[0]\n",
    "                best_obj.append(df_feas.loc[0, best_i])\n",
    "                best_gap.append(df_feas.loc[1, best_i])\n",
    "                lb_train.append(df_feas.loc[2, best_i])\n",
    "                lb_test.append(df_feas.loc[3, best_i])\n",
    "                true_prob.append(df_feas.loc[4, best_i])\n",
    "            \n",
    "            num_test_feas_found.append(sum(df.iloc[6,:]))\n",
    "            time_spent.append(sum(df.iloc[8,:]))\n",
    "            \n",
    "        prob_FF = count_FF / len(random_seed_data_settings)\n",
    "        true_prob_FF = count_true_FF / len(random_seed_data_settings)\n",
    "        avg_obj_F = np.mean(best_obj)\n",
    "        std_obj_F = np.std(best_obj)\n",
    "        avg_gap_F = np.mean(best_gap)\n",
    "        std_gap_F = np.std(best_gap)\n",
    "        avg_lb_train = np.mean(lb_train)\n",
    "        std_lb_train = np.std(lb_train)\n",
    "        avg_lb_test = np.mean(lb_test)\n",
    "        std_lb_test = np.std(lb_test)\n",
    "        avg_true_prob = np.mean(true_prob)\n",
    "        std_true_prob = np.std(true_prob)\n",
    "        avg_num_test_feas_found = np.mean(num_test_feas_found)\n",
    "        std_num_test_feas_found = np.std(num_test_feas_found)\n",
    "        avg_time_spent = np.mean(time_spent)\n",
    "        std_time_spent = np.std(time_spent)\n",
    "        \n",
    "        li = []\n",
    "        li.append(f'{prob_FF:.2f}')\n",
    "        li.append(f'{true_prob_FF:.2f}')\n",
    "        #li.append(f'{round(avg_obj,3):.3f}' + \" (\"+f'{round(std_obj,3):.3f}'+\")\")\n",
    "        if prob_FF > 0:\n",
    "            li.append(f'{round(avg_obj_F,3):.3f}' + \" (\"+f'{round(std_obj_F,3):.3f}'+\")\")\n",
    "            li.append(f'{round(avg_gap_F,3):.3f}' + \" (\"+f'{round(std_gap_F,3):.3f}'+\")\")\n",
    "        else:\n",
    "            li.append(\"-\")\n",
    "            li.append(\"-\")\n",
    "        li.append(f'{round(avg_lb_train,3):.3f}' + \" (\"+f'{round(std_lb_train,3):.3f}'+\")\")\n",
    "        li.append(f'{round(avg_lb_test,3):.3f}' + \" (\"+f'{round(std_lb_test,3):.3f}'+\")\")\n",
    "        li.append(f'{round(avg_true_prob,3):.3f}' + \" (\"+f'{round(std_true_prob,3):.3f}'+\")\")\n",
    "        li.append(f'{round(avg_num_test_feas_found,1):.1f}' + \" (\"+f'{round(std_num_test_feas_found,1):.1f}'+\")\")\n",
    "        li.append(f'{round(avg_time_spent,1):.1f}' + \" (\"+f'{round(std_time_spent,1):.1f}'+\")\")\n",
    "        \n",
    "        output_data_agg[(N_train, N_test, 'Best of 10 Split Runs')] = li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_agg = ['$N_{train}$', '$N_{test}$', 'Strategy',\n",
    "               'Prob.~FF', 'True Prob.~FF', 'Obj.~(Feas)', 'Gap (\\%)', '$LB_{train}$', '$LB_{test}$', 'True Prob.',\n",
    "              '\\# FF (test)', 'Time']\n",
    "\n",
    "dataio.write_output_to_latex(3, headers_agg, output_data_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bfddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot histograms for random seed output\n",
    "# Read from .txt file\n",
    "output_file_name = 'new_output'\n",
    "file_path = 'output/'+output_file_name+'.txt'\n",
    "dic = ''\n",
    "with open(file_path,'r') as f:\n",
    "         for i in f.readlines():\n",
    "            dic=i #string\n",
    "output_data_read = eval(dic)\n",
    "\n",
    "df = pd.DataFrame.from_dict(output_data_read, orient='index')\n",
    "#li1 = [col for col in df.columns if 'add + improve' == col[1]]\n",
    "\n",
    "df2 = pd.DataFrame({key: pd.Series(val) for key, val in output_data_read.items() if key[1] == 'add + improve + remove'})\n",
    "obj2 = df2.iloc[0,:].astype(float)\n",
    "\n",
    "title = 'Distribution of best found solution objective for random add + improve + remove'# for $\\beta = 0.95$, $\\alpha=10^{-6}$, $N_{1} = 1,000$, $N_{2} = 10,000$ and time limit $\\mathcal{L} = 1$ minute'\n",
    "dataio.plot_hist(obj2, 'Gap (%)', 'Frequency', title, 20, 0.75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
