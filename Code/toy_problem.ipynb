{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b1277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external packages\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import mosek\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# import internal packages\n",
    "import phi_divergence as phi\n",
    "from iter_gen_and_eval_alg import iter_gen_and_eval_alg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496bc27",
   "metadata": {},
   "source": [
    "The toy problem we examine is as follows:\n",
    "\n",
    "\\begin{align}\\label{toy_model_2}\n",
    "    \\begin{split}\n",
    "        \\max_{\\mathbf{0} \\leq \\mathbf{x} \\leq \\mathbf{10}}\\{\\mathbf{e}^T \\mathbf{x}: \\mathbf{\\xi}^T \\mathbf{x} \\leq 1,~\\sum_{j=1}^{k-1}x_j-x_k\\leq -1,~\\mathbf{x}\\leq 10\\}.\n",
    "    \\end{split}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "With $\\mathbf{x} \\in \\mathbb{R}^k$ and $\\mathbf{\\xi}\\in [-1,1]^{k}$ (assume uniformly distributed).\n",
    "\n",
    "We would like to obtain solutions for which we can make the following probabilistic guarantee regarding its feasibility: $$\\mathbb{P}^*(\\mathbf{\\xi}^T \\mathbf{x} \\leq 1)\\geq 1 - \\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem specific functions:\n",
    "def generate_data(random_seed, N, **kwargs):\n",
    "    np.random.seed(random_seed)\n",
    "    dim_x = kwargs.get('dim_x',2)\n",
    "    data = np.random.uniform(-1,1,size = (N,dim_x)) # generates N random scenarios    \n",
    "    return data \n",
    "\n",
    "def generate_data_with_nominal(random_seed, N, **kwargs):\n",
    "    np.random.seed(random_seed)\n",
    "    dim_x = kwargs.get('dim_x',2)\n",
    "    data_nominal = np.array([[0] * dim_x])\n",
    "    data = np.random.uniform(-1,1,size = (N-1,dim_x)) # generate N-1 scenarios\n",
    "    data = np.concatenate((data_nominal,data)) # add nominal case to training data\n",
    "    return data\n",
    "\n",
    "def solve_P_SCP(S, **kwargs):\n",
    "    dim_x = kwargs.get('dim_x', 2)\n",
    "    x = cp.Variable(dim_x, nonneg = True)\n",
    "    setup_time_start = time.time()\n",
    "    constraints = [cp.sum(x[0:(dim_x-1)]) <= x[dim_x-1]-1, x<=10]\n",
    "    for s in range(len(S)):\n",
    "        constraints.append(cp.multiply(S[s], x) - 1 <= 0)\n",
    "    obj = cp.Minimize(- cp.sum(x)) # formulate as a minimization problem\n",
    "    prob = cp.Problem(obj,constraints)\n",
    "    time_limit = kwargs.get('time_limit', 2*60*60) - (time.time() - setup_time_start)\n",
    "    if time_limit < 0:\n",
    "        print(\"Error: did not provide sufficient time for setting up & solving problem\")\n",
    "        return (None, None)\n",
    "    try:\n",
    "#         prob.solve(solver=cp.MOSEK, mosek_params = {mosek.dparam.optimizer_max_time: time_limit})\n",
    "        prob.solve(solver=cp.GUROBI, verbose=False, TimeLimit=time_limit)\n",
    "    except cp.error.SolverError:\n",
    "        return (None, None)\n",
    "    return (x.value, prob.value)\n",
    "\n",
    "def unc_func(x, data, **kwargs):\n",
    "    return (np.dot(data,x)) - 1\n",
    "\n",
    "def analytic_eval(x, problem_info):\n",
    "    dim_x = problem_info['dim_x']\n",
    "    return(1/2+1/(2*x[dim_x-1]))\n",
    "    \n",
    "def get_true_prob(x, dim_x):\n",
    "    return(1/2+1/(2*x[dim_x-1]))\n",
    "    \n",
    "def solve_toyproblem_true_prob(beta, dim_x):\n",
    "    x = cp.Variable(dim_x, nonneg = True)\n",
    "    constraints = [(1-2*beta)*x[dim_x-1] + 1 >= 0, cp.sum(x[0:(dim_x-1)]) <= x[dim_x-1]-1, x<=10]\n",
    "    obj = cp.Maximize(cp.sum(x))\n",
    "    prob = cp.Problem(obj,constraints)\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "    return(x.value, prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a8b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter values\n",
    "dim_x = 2\n",
    "problem_instance = {'dim_x': dim_x, 'time_limit': 10*60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c73db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and split data into train and test\n",
    "random_seed = 0\n",
    "N_total = 10000\n",
    "data = generate_data(random_seed, N_total, dim_x=dim_x)\n",
    "\n",
    "N_train = N_total / 2\n",
    "data_train, data_test = train_test_split(data, train_size=(N_train/N_total), random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b18899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our own algorithm parameter values\n",
    "risk_param_epsilon = 0.10\n",
    "conf_param_alpha = 0.05\n",
    "add_strategy = 'random_vio'\n",
    "remove_strategy = 'random_any'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f978590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide functions and other info for generating & evaluating solutions\n",
    "solve_SCP = solve_P_SCP\n",
    "eval_unc_obj = None\n",
    "eval_unc_constr = [{'function': unc_func,\n",
    "                    'info': {'risk_measure': 'probability', # must be either 'probability' or 'expectation'\n",
    "                             'desired_rhs': 1 - risk_param_epsilon}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the algorithm\n",
    "alg = iter_gen_and_eval_alg(solve_SCP, problem_instance, eval_unc_obj, eval_unc_constr, \n",
    "                            data_train, data_test, conf_param_alpha=conf_param_alpha,\n",
    "                            add_strategy=add_strategy ,remove_strategy=remove_strategy,\n",
    "                            verbose=True)\n",
    "\n",
    "stop_criteria={'max_elapsed_time': 0.5*60} # in seconds (time provided to search algorithm)\n",
    "\n",
    "(best_sol, runtime, num_iter, pareto_frontier, S_history) = alg.run(stop_criteria=stop_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f034ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3db6d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429175a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fc02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL:\n",
    "N_eval = 50000\n",
    "data_eval = generate_data(random_seed + 99, N_eval, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e87b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = problem_info['desired_prob_guarantee_beta']\n",
    "x_true, obj_true = solve_toyproblem_true_prob(beta, k)\n",
    "obj_alg = best_sol['obj']\n",
    "obj_gap_true =  100*(obj_true - obj_alg)/obj_true\n",
    "obj_gap_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b5fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal solution given data_test\n",
    "runtime, opt_x, opt_sum_y, opt_obj, opt_lb = util.compute_opt_given_data(conf_param_alpha, beta, phi_div, phi_dot, data_test)\n",
    "obj_alg = best_sol['obj']\n",
    "obj_gap_opt = 100*(opt_obj - obj_alg)/opt_obj\n",
    "obj_gap_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1c912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,sol in enumerate(solutions):\n",
    "    if i<=7:\n",
    "        Z_arr = data_train[sol['scenario_set']]\n",
    "        true_prob = get_true_prob(sol['sol'], k)\n",
    "        if i == 0:\n",
    "            dataio.plot_iter(i, data_train, Z_arr, sol['sol'], sol['obj'], \n",
    "                             sol['p_train'], sol['lb_train'], true_prob,\n",
    "                             True, \"png\", True, N_train, alpha, beta)\n",
    "        else:\n",
    "            dataio.plot_iter(i, data_train, Z_arr, sol['sol'], sol['obj'], \n",
    "                             sol['p_train'], sol['lb_train'], true_prob,\n",
    "                             True, \"png\", False, N_train, alpha, beta)\n",
    "        \n",
    "            dataio.plot_iter(i, data_test, None, sol['sol'], sol['obj'], \n",
    "                             sol['p_test'], sol['lb_test'], true_prob,\n",
    "                             True, \"png\", False, N_test, alpha, beta)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287d75d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataio.plot_pareto_curve(pareto_solutions, beta, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86a966",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataio.plot_obj_over_time(solutions, best_sol, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9e83c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataio.plot_size_set_over_time(solutions, best_sol, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc263207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3502e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final solution found by algorithm\n",
    "name = 'Strategy: '+ str(add_strategy)\n",
    "save_plot = False\n",
    "plot_type = \"eps\"\n",
    "show_legend = True\n",
    "Z_values = data_train[best_sol['scenario_set']]\n",
    "dataio.plot_solution(name, data_train, Z_values, best_sol['sol'], \n",
    "              best_sol['obj'], best_sol['lb_test'], save_plot, plot_type, show_legend, N, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db1778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute optimal solution with true probability constraint\n",
    "prob_true = beta\n",
    "[x_true, obj_true] = solve_toyproblem_true_prob(prob_true, k)\n",
    "constr = uncertain_constraint(data_test, x_true)\n",
    "vio = constr[constr>(0+numeric_precision)]   \n",
    "p_vio = len(vio)/N_train\n",
    "p = np.array([1-p_vio, p_vio])\n",
    "r = phi_dot/(2*N_test)*scipy.stats.chi2.ppf(1-alpha, 1)\n",
    "lb = rs.compute_lb(p, r, par, phi_div)\n",
    "print(p)\n",
    "print(lb)\n",
    "print(obj_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3dbb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"TrueProb=\"+str(prob_true)\n",
    "save_plot = False\n",
    "plot_type = \"eps\"\n",
    "show_legend = True\n",
    "dataio.plot_solution(name, data_test, None, x_true, obj_true, lb, save_plot, plot_type, show_legend, N, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal solution given data_test\n",
    "runtime, opt_x, opt_sum_y, opt_obj, opt_lb = util.compute_opt_given_data(alpha, beta, par, phi_div, data_test, time_limit_mosek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4134aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea770992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optimal solution given data_test\n",
    "name = 'Opt_given_test_data'\n",
    "save_plot = False\n",
    "plot_type = \"eps\"\n",
    "show_legend = True\n",
    "dataio.plot_solution(name, data_test, None, opt_x, opt_obj, opt_lb, save_plot, plot_type, show_legend, N, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ddec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute solution via Campi method\n",
    "data = generate_data(k, N_campi)\n",
    "runtime, campi_x, campi_obj, campi_true_prob, Z_arr = util.solve_with_campi_N(alpha, beta, numeric_precision, data, time_limit_mosek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Campi solution\n",
    "name = 'Campi method'\n",
    "save_plot = False\n",
    "plot_type = \"eps\"\n",
    "show_legend = True\n",
    "dataio.plot_solution(name, data, Z_arr, campi_x, campi_obj, 0, save_plot, plot_type, show_legend, N, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58becfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00682b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Garatti2022 solution\n",
    "k = 1000\n",
    "dim_x = k\n",
    "beta = 0.95\n",
    "alpha = 10e-6\n",
    "time_limit_solve = 5*60\n",
    "numeric_precision = 1e-6\n",
    "\n",
    "set_sizes, time_determine_set_sizes = util.Garatti2022_determine_set_sizes(dim_x, beta, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55332b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed_settings = [i for i in range(1, 11)]\n",
    "\n",
    "# Store output in lists\n",
    "import statistics as s\n",
    "vec_obj = []\n",
    "vec_true_prob = []\n",
    "vec_mean_size_S = []\n",
    "vec_max_size_S = []\n",
    "vec_num_iter = []\n",
    "vec_time = []\n",
    "vec_data = []\n",
    "\n",
    "run_count = 0\n",
    "for random_seed in random_seed_settings:\n",
    "    (x, obj, j, s_j, set_sizes, \n",
    "     time_main_solves, \n",
    "     time_determine_supp) = util.solve_with_Garatti2022(dim_x, set_sizes, solve_SCP, uncertain_constraint, \n",
    "                               generate_data, random_seed, time_limit_solve,\n",
    "                               numeric_precision)\n",
    "    \n",
    "    true_prob = get_true_prob(x, k)\n",
    "    total_time = time_determine_set_sizes + time_main_solves + time_determine_supp\n",
    "    mean_size_S = s.mean([set_sizes[i] for i in range(0,j+1)])\n",
    "    max_size_S = set_sizes[j]\n",
    "    \n",
    "    # add to output data:\n",
    "    vec_obj.append(obj)\n",
    "    vec_true_prob.append(true_prob)\n",
    "    vec_mean_size_S.append(mean_size_S)\n",
    "    vec_max_size_S.append(max_size_S)\n",
    "    vec_num_iter.append(j)\n",
    "    vec_time.append(total_time)\n",
    "    vec_data.append(max_size_S)\n",
    "    \n",
    "    run_count += 1\n",
    "    print(run_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbadd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now output mean and std in proper string format\n",
    "import statistics as s\n",
    "\n",
    "print(f'{round(s.mean(vec_obj),3):.3f}' + \" (\"+f'{round(s.stdev(vec_obj),3):.3f}'+\")\")\n",
    "print(f'{round(s.mean(vec_true_prob),3):.3f}' + \" (\"+f'{round(s.stdev(vec_true_prob),3):.3f}'+\")\")\n",
    "print(f'{round(s.mean(vec_mean_size_S),1):.1f}' + \" (\"+f'{round(s.stdev(vec_mean_size_S),1):.1f}'+\")\")\n",
    "print(f'{round(s.mean(vec_max_size_S),1):.1f}' + \" (\"+f'{round(s.stdev(vec_max_size_S),1):.1f}'+\")\")\n",
    "print(f'{round(s.mean(vec_num_iter),1):.1f}' + \" (\"+f'{round(s.stdev(vec_num_iter),1):.1f}'+\")\")\n",
    "print(f'{round(s.mean(vec_time),1):.1f}' + \" (\"+f'{round(s.stdev(vec_time),1):.1f}'+\")\")\n",
    "print(f'{round(s.mean(vec_data),1):.1f}' + \" (\"+f'{round(s.stdev(vec_data),1):.1f}'+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2219b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d2a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Calafiore2016 solution\n",
    "k = 10\n",
    "dim_x = k\n",
    "beta = 0.95\n",
    "alpha = 10e-6\n",
    "time_limit_solve = 5*60\n",
    "numeric_precision = 1e-6\n",
    "\n",
    "scale_eps_prime = 0.7\n",
    "N_eval = 10000\n",
    "\n",
    "N, time_determine_set_sizes = util.determine_N_calafiore2016(dim_x, beta, alpha, scale_eps_prime, N_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419c0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd72b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed_settings = [i for i in range(1, 11)]\n",
    "\n",
    "# Store output in lists\n",
    "import statistics as s\n",
    "vec_obj = []\n",
    "vec_true_prob = []\n",
    "vec_mean_size_S = []\n",
    "vec_max_size_S = []\n",
    "vec_num_iter = []\n",
    "vec_time = []\n",
    "vec_data = []\n",
    "\n",
    "run_count = 0\n",
    "for random_seed in random_seed_settings:\n",
    "    (x, obj, iter_j, \n",
    "     total_train_data_used, \n",
    "     total_test_data_used, \n",
    "     total_time) = util.solve_with_calafiore2016(N, N_eval, scale_eps_prime, dim_x, beta, alpha, solve_SCP, uncertain_constraint, \n",
    "                                            generate_data, random_seed, time_limit_solve,\n",
    "                                            numeric_precision)\n",
    "    \n",
    "    true_prob = get_true_prob(x, k)\n",
    "    total_time = total_time\n",
    "    mean_size_S = N\n",
    "    max_size_S = N\n",
    "    total_data_used = total_train_data_used + total_test_data_used\n",
    "    \n",
    "    # add to output data:\n",
    "    vec_obj.append(obj)\n",
    "    vec_true_prob.append(true_prob)\n",
    "    vec_mean_size_S.append(mean_size_S)\n",
    "    vec_max_size_S.append(max_size_S)\n",
    "    vec_num_iter.append(iter_j)\n",
    "    vec_time.append(total_time)\n",
    "    vec_data.append(total_data_used)\n",
    "    \n",
    "    run_count += 1\n",
    "    print(run_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b777a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now output mean and std in proper string format\n",
    "import statistics as s\n",
    "\n",
    "print(f'{round(s.mean(vec_obj),3):.3f}' + \" (\"+f'{round(s.stdev(vec_obj),3):.3f}'+\")\")\n",
    "print(f'{round(s.mean(vec_true_prob),3):.3f}' + \" (\"+f'{round(s.stdev(vec_true_prob),3):.3f}'+\")\")\n",
    "print(f'{round(s.mean(vec_mean_size_S),1):.1f}' + \" (\"+f'{round(s.stdev(vec_mean_size_S),1):.1f}'+\")\")\n",
    "print(f'{round(s.mean(vec_max_size_S),1):.1f}' + \" (\"+f'{round(s.stdev(vec_max_size_S),1):.1f}'+\")\")\n",
    "print(f'{round(s.mean(vec_num_iter),1):.1f}' + \" (\"+f'{round(s.stdev(vec_num_iter),1):.1f}'+\")\")\n",
    "print(f'{round(s.mean(vec_time),1):.1f}' + \" (\"+f'{round(s.stdev(vec_time),1):.1f}'+\")\")\n",
    "print(f'{round(s.mean(vec_data),1):.1f}' + \" (\"+f'{round(s.stdev(vec_data),1):.1f}'+\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1433f0c8",
   "metadata": {},
   "source": [
    "# The following cells are used to obtain output and write to latex tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f27e396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_file_name = 'new_output_data'\n",
    "\n",
    "headers = ['$k$', 'seed', '$n_{\\mathcal{X}}$',\n",
    "           'Obj.~(RS)', 'Obj.~(TP)', 'Gap TP.~(\\%)', \n",
    "           'Obj.~($\\mathcal{D}^{\\\\text{test}}_{N_2}$)', 'Gap $\\mathcal{D}^{\\\\text{test}}_{N_2}$ (\\%)',\n",
    "           'Time', '$|\\mathcal{X}|$']\n",
    "\n",
    "# Write headers to .txt file\n",
    "with open(r'output/headers_'+output_file_name+'.txt','w+') as f:\n",
    "    f.write(str(headers))\n",
    "\n",
    "output_data = {}\n",
    "\n",
    "# Variable parameter values\n",
    "k_settings = [2]#, 10, 100]#, 1000]\n",
    "random_seed_settings = [i for i in range(1, 4)]\n",
    "n_sol_settings = [1, 100, 500, 1000, 5000, 10000]\n",
    "\n",
    "# Fixed parameter values\n",
    "N_total = 500\n",
    "p_train = 0.5\n",
    "risk_measure = 'chance_constraint' # options: 'chance_constraint', 'exp_constraint'\n",
    "alpha = 0.01\n",
    "beta = 0.90\n",
    "\n",
    "# LB-related parameters\n",
    "par = 1\n",
    "phi_div = phi.mod_chi2_cut\n",
    "phi_dot = 2\n",
    "numeric_precision = 1e-6 # To correct for floating-point math operations\n",
    "\n",
    "# RS-related parameters\n",
    "time_limit_search = 15*60\n",
    "time_limit_solve = 5*60 # in seconds\n",
    "max_nr_solutions = 10000 # for easy problems with long time limits, we may want extra restriction\n",
    "add_strategy = 'random_vio'\n",
    "remove_strategy = 'random_any'\n",
    "clean_strategy = (30000, 'random_inactive')\n",
    "add_remove_threshold = 0.0 # controls the ambiguity around adding/removing\n",
    "use_tabu = False\n",
    "\n",
    "N_train = round(p_train * N_total)\n",
    "N_test = N_total - N_train\n",
    "\n",
    "run_count = 0\n",
    "for k in k_settings:\n",
    "    \n",
    "    # Compute true opt\n",
    "    x_true, obj_true = solve_toyproblem_true_prob(beta, k)\n",
    "    \n",
    "    for random_seed in random_seed_settings:  \n",
    "        \n",
    "        #data = generate_data(random_seed, k, N_total)\n",
    "        #data_train, data_test = train_test_split(data, train_size=(N_train/N_total), random_state=random_seed)\n",
    "        \n",
    "        data_train = generate_data(random_seed, k, N_train)\n",
    "        data_test = generate_data(random_seed, k, N_test)\n",
    "\n",
    "        # compute opt given data_test\n",
    "        runtime_opt, x_opt, sum_y, obj_opt, p_min_opt = util.compute_opt_given_data(alpha, beta, par, phi_div, phi_dot, \n",
    "                                                                               data_test, time_limit_solve)\n",
    "        \n",
    "            \n",
    "        # Gen and eval algorithm\n",
    "        (runtime, num_iter, solutions, \n",
    "         best_sol, pareto_solutions) = rs.gen_and_eval_alg(data_train, data_test, beta, alpha, time_limit_search, time_limit_solve, \n",
    "                                                    max_nr_solutions, add_strategy, remove_strategy, clean_strategy, \n",
    "                                                    add_remove_threshold, use_tabu,\n",
    "                                                    phi_div, phi_dot, numeric_precision,\n",
    "                                                    solve_SCP, uncertain_constraint, risk_measure, random_seed)\n",
    "\n",
    "\n",
    "        for i,n_sol in enumerate(n_sol_settings):\n",
    "            if i == 0 and len(solutions) == 0:\n",
    "                output_data[(k, random_seed, n_sol)] = [np.nan,\n",
    "                                                         obj_true,\n",
    "                                                         np.nan,\n",
    "                                                         obj_opt,\n",
    "                                                         np.nan,\n",
    "                                                         runtime,\n",
    "                                                         0]\n",
    "                break\n",
    "\n",
    "            elif i == 0 or (i > 0 and len(solutions) > n_sol_settings[i-1]):\n",
    "\n",
    "                sub_solutions = solutions[0:n_sol]\n",
    "                time = sub_solutions[-1]['time']\n",
    "                best_in_sub_sol = {'sol': None}\n",
    "                for sol_info in sub_solutions:\n",
    "                    obj = sol_info['obj']\n",
    "                    lb = sol_info['lb_test']\n",
    "                    if best_in_sub_sol['sol'] is None or (best_in_sub_sol['lb_test'] < beta and lb > best_in_sub_sol['lb_test']):\n",
    "                        best_in_sub_sol = sol_info\n",
    "                    elif ((lb >= beta and obj > best_in_sub_sol['obj']) \n",
    "                          or (lb > best_in_sub_sol['lb_test'] and obj >= best_in_sub_sol['obj'])):\n",
    "                        best_in_sub_sol = sol_info\n",
    "\n",
    "                obj_rs = best_in_sub_sol['obj']\n",
    "                obj_gap_true = 100*(obj_true - obj_rs)/obj_true\n",
    "                obj_gap_opt = 100*(obj_opt - obj_rs)/obj_opt\n",
    "\n",
    "                output_data[(k, random_seed, n_sol)] = [obj_rs,\n",
    "                                                         obj_true,\n",
    "                                                         obj_gap_true,\n",
    "                                                         obj_opt,\n",
    "                                                         obj_gap_opt,\n",
    "                                                         time,\n",
    "                                                         len(sub_solutions)]\n",
    "\n",
    "\n",
    "        output_file_name = 'new_output_data'\n",
    "        with open(r'output/'+output_file_name+'.txt','w+') as f:\n",
    "            f.write(str(output_data))\n",
    "\n",
    "        run_count += 1\n",
    "        print(\"Completed run: \" + str(run_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf84fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_str = {}\n",
    "for i,res in output_data.items():\n",
    "    res_str = []\n",
    "    for i2,el in enumerate(res):\n",
    "        if i2 < 5:\n",
    "            if np.isnan(el):\n",
    "                res_str.append('-')\n",
    "            else:\n",
    "                res_str.append(f'{round(el,2):.2f}') \n",
    "        elif i2 == 5:\n",
    "            res_str.append(f'{round(el,0):.0f}') \n",
    "        else:\n",
    "            res_str.append(el)\n",
    "    \n",
    "    output_data_str[i] = res_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e646b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['$k$', 'seed', 'remove strategy', '$n_{\\mathcal{X}}$',\n",
    "           'Obj.~(RS)', 'Obj.~(TP)', 'Gap TP.~(\\%)', \n",
    "           'Obj.~($\\mathcal{D}^{\\\\text{test}}_{N_2}$)', 'Gap $\\mathcal{D}^{\\\\text{test}}_{N_2}$ (\\%)',\n",
    "           'Time', '$|\\mathcal{X}|$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataio.write_output_to_latex(4, headers, output_data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'new_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write headers + output to .txt file\n",
    "with open(r'output/headers_'+output_file_name+'.txt','w+') as f:\n",
    "    f.write(str(headers))\n",
    "\n",
    "# with open(r'output/'+output_file_name+'.txt','w+') as f:\n",
    "#     f.write(str(output_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3a33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e66771",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'eval_gap_as_L_to_inf_k=[2,10]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e164f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read from .txt file\n",
    "file_path = 'output/'+output_file_name+'.txt'\n",
    "dic = ''\n",
    "with open(file_path,'r') as f:\n",
    "         for i in f.readlines():\n",
    "            dic=i #string\n",
    "output_data_read = eval(dic)\n",
    "output_data_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239c73f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_data = output_data_read\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f52d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from .txt file\n",
    "file_path = 'output/headers_'+output_file_name+'.txt'\n",
    "dic = ''\n",
    "with open(file_path,'r') as f:\n",
    "         for i in f.readlines():\n",
    "            dic=i #string\n",
    "output_data_headers_read = eval(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc1ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = output_data_headers_read\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df061a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataio.write_output_to_latex(3, headers, output_data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de736569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "k = 1000\n",
    "beta = 0.9\n",
    "N_total_settings = [100]\n",
    "p_train_settings = [0.25, 0.5, 0.75]\n",
    "random_seed_data_settings = [i for i in range(1, 7)]\n",
    "random_seed_split_settings = [i for i in range(1, 11)]\n",
    "\n",
    "output_data_agg = {}\n",
    "for N_total in N_total_settings:\n",
    "    for p_train in p_train_settings:\n",
    "        \n",
    "        N_train = round(p_train * N_total)\n",
    "        N_test = N_total - N_train\n",
    "        \n",
    "        df = pd.DataFrame({key: pd.Series(val) for key, val in output_data.items() if (key[0] == N_train\n",
    "                                                                                       and key[1] == N_test\n",
    "                                                                                       and key[2] in random_seed_data_settings)})\n",
    "        df = df.astype(float)\n",
    "        df_agg = df.agg([\"mean\",\"std\"], axis=\"columns\")\n",
    "\n",
    "        df_feas = df.loc[:,df.iloc[3,:] >= beta]\n",
    "        df_feas_agg = df_feas.agg([\"mean\",\"std\"], axis=\"columns\")\n",
    "\n",
    "        prob_FF = sum(df.iloc[3,:] >= beta) / len(df.columns)\n",
    "        true_prob_FF = sum(df.iloc[4,:] >= beta) / len(df.columns)\n",
    "\n",
    "        avg_obj = df_agg.loc[0,'mean']\n",
    "        std_obj = df_agg.loc[0,'std']\n",
    "\n",
    "        if prob_FF > 0:\n",
    "            avg_obj_F = df_feas_agg.loc[0, 'mean']\n",
    "            std_obj_F = df_feas_agg.loc[0, 'std']\n",
    "            avg_gap_F = df_feas_agg.loc[1, 'mean']\n",
    "            std_gap_F = df_feas_agg.loc[1, 'std']\n",
    "        else:\n",
    "            avg_obj_F = 0\n",
    "            std_obj_F = 0\n",
    "            avg_gap_F = 0\n",
    "            std_gap_F = 0\n",
    "\n",
    "        avg_lb_train = df_agg.loc[2,'mean']\n",
    "        std_lb_train = df_agg.loc[2,'std']\n",
    "        avg_lb_test = df_agg.loc[3,'mean']\n",
    "        std_lb_test = df_agg.loc[3,'std']\n",
    "        avg_true_prob = df_agg.loc[4,'mean']\n",
    "        std_true_prob = df_agg.loc[4,'std']\n",
    "        \n",
    "        avg_num_test_feas_found = df_agg.loc[6,'mean']\n",
    "        std_num_test_feas_found = df_agg.loc[6,'std']\n",
    "        \n",
    "        avg_time_spent = df_agg.loc[8,'mean']\n",
    "        std_time_spent = df_agg.loc[8,'std']\n",
    "\n",
    "        li = []\n",
    "        li.append(f'{prob_FF:.2f}')\n",
    "        li.append(f'{true_prob_FF:.2f}')\n",
    "        #li.append(f'{round(avg_obj,3):.3f}' + \" (\"+f'{round(std_obj,3):.3f}'+\")\")\n",
    "        if prob_FF > 0:\n",
    "            li.append(f'{round(avg_obj_F,3):.3f}' + \" (\"+f'{round(std_obj_F,3):.3f}'+\")\")\n",
    "            li.append(f'{round(avg_gap_F,3):.3f}' + \" (\"+f'{round(std_gap_F,3):.3f}'+\")\")\n",
    "        else:\n",
    "            li.append(\"-\")\n",
    "            li.append(\"-\")\n",
    "        li.append(f'{round(avg_lb_train,3):.3f}' + \" (\"+f'{round(std_lb_train,3):.3f}'+\")\")\n",
    "        li.append(f'{round(avg_lb_test,3):.3f}' + \" (\"+f'{round(std_lb_test,3):.3f}'+\")\")\n",
    "        li.append(f'{round(avg_true_prob,3):.3f}' + \" (\"+f'{round(std_true_prob,3):.3f}'+\")\")\n",
    "        li.append(f'{round(avg_num_test_feas_found,1):.1f}' + \" (\"+f'{round(std_num_test_feas_found,1):.1f}'+\")\")\n",
    "        li.append(f'{round(avg_time_spent,1):.1f}' + \" (\"+f'{round(std_time_spent,1):.1f}'+\")\")\n",
    "\n",
    "        output_data_agg[(N_train, N_test, 'Single Split Run')] = li\n",
    "        \n",
    "        \n",
    "        count_FF = 0\n",
    "        count_true_FF = 0\n",
    "        best_obj = []\n",
    "        best_gap = []\n",
    "        lb_train = []\n",
    "        lb_test = []\n",
    "        true_prob = []\n",
    "        num_test_feas_found = []\n",
    "        time_spent = []\n",
    "        \n",
    "        for random_seed_data in random_seed_data_settings:\n",
    "            df = pd.DataFrame({key: pd.Series(val) for key, val in output_data.items() if (key[0] == N_train\n",
    "                                                                                       and key[1] == N_test\n",
    "                                                                                       and key[2] == random_seed_data)})\n",
    "            \n",
    "            if sum(df.iloc[3,:] >= beta) > 0:\n",
    "                count_FF += 1\n",
    "            if sum(df.iloc[4,:] >= beta) > 0:\n",
    "                count_true_FF += 1\n",
    "                \n",
    "            df_feas = df.loc[:,df.iloc[3,:] >= beta]\n",
    "            #df_feas_agg = df_feas.agg([\"mean\",\"std\",\"max\", \"min\"], axis=\"columns\")\n",
    "            if not df_feas.empty:\n",
    "                best_i = df_feas.idxmax(axis=1)[0]\n",
    "                best_obj.append(df_feas.loc[0, best_i])\n",
    "                best_gap.append(df_feas.loc[1, best_i])\n",
    "                lb_train.append(df_feas.loc[2, best_i])\n",
    "                lb_test.append(df_feas.loc[3, best_i])\n",
    "                true_prob.append(df_feas.loc[4, best_i])\n",
    "            \n",
    "            num_test_feas_found.append(sum(df.iloc[6,:]))\n",
    "            time_spent.append(sum(df.iloc[8,:]))\n",
    "            \n",
    "        prob_FF = count_FF / len(random_seed_data_settings)\n",
    "        true_prob_FF = count_true_FF / len(random_seed_data_settings)\n",
    "        avg_obj_F = np.mean(best_obj)\n",
    "        std_obj_F = np.std(best_obj)\n",
    "        avg_gap_F = np.mean(best_gap)\n",
    "        std_gap_F = np.std(best_gap)\n",
    "        avg_lb_train = np.mean(lb_train)\n",
    "        std_lb_train = np.std(lb_train)\n",
    "        avg_lb_test = np.mean(lb_test)\n",
    "        std_lb_test = np.std(lb_test)\n",
    "        avg_true_prob = np.mean(true_prob)\n",
    "        std_true_prob = np.std(true_prob)\n",
    "        avg_num_test_feas_found = np.mean(num_test_feas_found)\n",
    "        std_num_test_feas_found = np.std(num_test_feas_found)\n",
    "        avg_time_spent = np.mean(time_spent)\n",
    "        std_time_spent = np.std(time_spent)\n",
    "        \n",
    "        li = []\n",
    "        li.append(f'{prob_FF:.2f}')\n",
    "        li.append(f'{true_prob_FF:.2f}')\n",
    "        #li.append(f'{round(avg_obj,3):.3f}' + \" (\"+f'{round(std_obj,3):.3f}'+\")\")\n",
    "        if prob_FF > 0:\n",
    "            li.append(f'{round(avg_obj_F,3):.3f}' + \" (\"+f'{round(std_obj_F,3):.3f}'+\")\")\n",
    "            li.append(f'{round(avg_gap_F,3):.3f}' + \" (\"+f'{round(std_gap_F,3):.3f}'+\")\")\n",
    "        else:\n",
    "            li.append(\"-\")\n",
    "            li.append(\"-\")\n",
    "        li.append(f'{round(avg_lb_train,3):.3f}' + \" (\"+f'{round(std_lb_train,3):.3f}'+\")\")\n",
    "        li.append(f'{round(avg_lb_test,3):.3f}' + \" (\"+f'{round(std_lb_test,3):.3f}'+\")\")\n",
    "        li.append(f'{round(avg_true_prob,3):.3f}' + \" (\"+f'{round(std_true_prob,3):.3f}'+\")\")\n",
    "        li.append(f'{round(avg_num_test_feas_found,1):.1f}' + \" (\"+f'{round(std_num_test_feas_found,1):.1f}'+\")\")\n",
    "        li.append(f'{round(avg_time_spent,1):.1f}' + \" (\"+f'{round(std_time_spent,1):.1f}'+\")\")\n",
    "        \n",
    "        output_data_agg[(N_train, N_test, 'Best of 10 Split Runs')] = li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_agg = ['$N_{train}$', '$N_{test}$', 'Strategy',\n",
    "               'Prob.~FF', 'True Prob.~FF', 'Obj.~(Feas)', 'Gap (\\%)', '$LB_{train}$', '$LB_{test}$', 'True Prob.',\n",
    "              '\\# FF (test)', 'Time']\n",
    "\n",
    "dataio.write_output_to_latex(3, headers_agg, output_data_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bfddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot histograms for random seed output\n",
    "# Read from .txt file\n",
    "output_file_name = 'new_output'\n",
    "file_path = 'output/'+output_file_name+'.txt'\n",
    "dic = ''\n",
    "with open(file_path,'r') as f:\n",
    "         for i in f.readlines():\n",
    "            dic=i #string\n",
    "output_data_read = eval(dic)\n",
    "\n",
    "df = pd.DataFrame.from_dict(output_data_read, orient='index')\n",
    "#li1 = [col for col in df.columns if 'add + improve' == col[1]]\n",
    "\n",
    "df2 = pd.DataFrame({key: pd.Series(val) for key, val in output_data_read.items() if key[1] == 'add + improve + remove'})\n",
    "obj2 = df2.iloc[0,:].astype(float)\n",
    "\n",
    "title = 'Distribution of best found solution objective for random add + improve + remove'# for $\\beta = 0.95$, $\\alpha=10^{-6}$, $N_{1} = 1,000$, $N_{2} = 10,000$ and time limit $\\mathcal{L} = 1$ minute'\n",
    "dataio.plot_hist(obj2, 'Gap (%)', 'Frequency', title, 20, 0.75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
