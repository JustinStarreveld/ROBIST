{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64b1277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external packages\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import mosek\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# import internal packages\n",
    "import phi_divergence as phi\n",
    "from iter_gen_and_eval_alg import iter_gen_and_eval_alg\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496bc27",
   "metadata": {},
   "source": [
    "The problem we examine is as follows:\n",
    "\n",
    "Consider a company that sells $n$ different products, which it is able to produce with the use of $m$ different machines. \n",
    "\n",
    "The goal is to determine an optimal production plan, which specifies the amount of time $y_{jk}$ that each machine $j=1,\\dots,m$ will be used for producing product $k = 1,\\dotsc,n$. An optimal plan is one that maximizes the total profit of the company subject to availability constraints.\n",
    "\n",
    "Each machine $j$ may only be used for a limited amount of time $a_j$ and incurs operating costs $c_{jk}$ per unit of product $k$ that is produced. Each unit of product $k$ can be sold at a price of $u_k$ and leftover units incur inventory holding costs of $\\tilde{c}_{k}$. For this problem there are two uncertain parameters, the demand $d_k$ for each product $k$ and the quantity $p_{jk}$ of product $k$ that is produced per time unit by machine $j$. \n",
    "\n",
    "Putting all this together, we arrive at the following mathematical formulation:\n",
    "\\begin{align}\n",
    "    \\label{mathform:weighted_dist_1:obj}\n",
    "    \\min_{\\mathbf{y}}&~\\sum_{j=1}^{m} \\sum_{k=1}^{n} c_{jk} y_{jk} + \\sum_{k=1}^{n} \\tilde{c}_{k} \\left[ \\sum_{j=1}^{m} p_{jk} y_{jk} - d_k \\right]_{+} - \\sum_{k=1}^{n} u_k \\min \\left( \\sum_{j=1}^{m} p_{jk} y_{jk}, d_k \\right) \\\\\n",
    "    \\text{s.t.}&~\\sum_{k=1}^{n} y_{jk} \\leq a_j, && j=1.\\dotsc,m \\label{mathform:weighted_dist_1:limit_time}\\\\\n",
    "    &~y_{jk} \\geq 0, && j=1.\\dotsc,m, k=1.\\dotsc,n, \\label{mathform:weighted_dist_1:xVarNonNeg}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "where $[ a ]_{+}$ is equivalent to $\\max\\{a,0\\}$. The $\\max$ and $\\min$ functions make this a nonlinear optimization problem. As such, it is quite a tricky problem to deal with using conventional Robust Optimization techniques. \n",
    "\n",
    "Note that this problem can also be easily converted into the notation used earlier for by moving the uncertainty into the constraints and introducing supplementary variable $\\theta$.\n",
    "Let $\\mathbf{x} = (\\mathbf{y}, \\theta)$ and $\\mathscr{X} = \\{ \\mathbf{x} : \\sum_{k=1}^{n} y_{jk} \\leq a_j, j=1.\\dotsc,m, \\mathbf{y} \\geq 0 \\}$. We can rewrite the problem as:\n",
    "\\begin{align}\n",
    "    \\label{mathform:weighted_dist_2:obj}\n",
    "    \\min_{\\mathbf{x} \\in \\mathscr{X}}&~\\sum_{j=1}^{m} \\sum_{k=1}^{n} c_{jk} y_{jk} + \\theta  \\\\\n",
    "    \\text{s.t.}&~\\sum_{k=1}^{n} \\tilde{c}_{k} \\left[ \\sum_{j=1}^{m} p_{jk} y_{jk} - d_k \\right]_{+} - \\sum_{k=1}^{n} u_k \\min \\left( \\sum_{j=1}^{m} p_{jk} y_{jk}, d_k \\right) - \\theta \\leq 0.\n",
    "\\end{align}\n",
    "\n",
    "By defining $g(\\mathbf{x}) = \\sum_{j=1}^{m} \\sum_{k=1}^{n} c_{jk} y_{jk} + \\theta$ and $f(\\mathbf{x}, \\mathbf{z}) = \\sum_{k=1}^{n} \\tilde{c}_{k} \\left[ \\sum_{j=1}^{m} p_{jk} y_{jk} - d_k \\right]_{+} - \\sum_{k=1}^{n} u_k \\min \\left( \\sum_{j=1}^{m} p_{jk} y_{jk}, d_k \\right) - \\theta$ we obtain the familiar notation used throughout this paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem specific functions:\n",
    "def generate_unc_param_data(random_seed, N, **kwargs):\n",
    "    np.random.seed(random_seed)\n",
    "    m = 5\n",
    "    n = 10\n",
    "    \n",
    "    # generate demand vector param\n",
    "    d_nom = (25, 38, 18, 39, 60, 35, 41, 22, 74, 30)\n",
    "    d = np.random.default_rng().dirichlet(d_nom, N) * 382\n",
    "    \n",
    "    # generate production efficiency param\n",
    "    p_nom = np.array([[5.0, 7.6, 3.6, 7.8, 12.0, 7.0, 8.2, 4.4, 14.8, 6.0],\n",
    "                      [3.8, 5.8, 2.8, 6.0, 9.2, 5.4, 6.3, 3.4, 11.4, 4.6],\n",
    "                      [2.3, 3.5, 1.6, 3.5, 5.5, 3.2, 3.7, 2.0, 6.7, 2.7],\n",
    "                      [2.6, 4.0, 1.9, 4.1, 6.3, 3.7, 4.3, 2.3, 7.8, 3.2],\n",
    "                      [2.4, 3.6, 1.7, 3.7, 5.7, 3.3, 3.9, 2.1, 7.0, 2.9]])\n",
    "    p = np.random.random_sample(size = (N,m,n)) * (p_nom*1.05 - p_nom*0.95) + (p_nom*0.95)\n",
    "    data = list(zip(d,p))\n",
    "    return data\n",
    "\n",
    "def get_fixed_param_data():\n",
    "    # fixed parameter values from Care (2014)\n",
    "    C = np.array([[1.8, 2.2, 1.5, 2.2, 2.6, 2.1, 2.2, 1.7, 2.8, 1.9],\n",
    "                  [1.6, 1.9, 1.3, 1.9, 2.3, 1.9, 2.0, 1.5, 2.5, 1.7],\n",
    "                  [1.2, 1.5, 1.0, 1.5, 1.9, 1.4, 1.6, 1.1, 2.0, 1.3],\n",
    "                  [1.3, 1.6, 1.1, 1.6, 2.0, 1.5, 1.7, 1.2, 2.2, 1.4],\n",
    "                  [1.2, 1.5, 1.0, 1.6, 1.9, 1.5, 1.6, 1.1, 2.1, 1.3]])\n",
    "\n",
    "    A = np.array([10, 13, 22, 19, 21])\n",
    "    C_tilde = np.array([1.3, 1.3, 1.3, 1.3, 1.3, 1.3, 1.3, 1.3, 1.3, 1.3])\n",
    "    U = np.array([1.5, 1.8, 1.2, 1.9, 2.2, 1.8, 1.9, 1.4, 2.4, 1.6])\n",
    "    param_dict = {'C':C, 'A':A, 'C_tilde': C_tilde, 'U': U}\n",
    "    return param_dict\n",
    "\n",
    "def solve_P_SCP(S, **kwargs):\n",
    "    # get fixed parameter values\n",
    "    C = kwargs['C']\n",
    "    A = kwargs['A']\n",
    "    C_tilde = kwargs['C_tilde']\n",
    "    U = kwargs['U']\n",
    "    \n",
    "    # unzip uncertain parameters\n",
    "    d,p = zip(*S)\n",
    "    \n",
    "    # get dimensions of problem\n",
    "    m,n = p[0].shape\n",
    "    num_scen = len(d)\n",
    "    \n",
    "    # create variables\n",
    "    theta = cp.Variable(1)\n",
    "    y = cp.Variable((m, n), nonneg = True)\n",
    "    \n",
    "    # set up problem\n",
    "    constraints = []\n",
    "    for s in range(num_scen):\n",
    "        unc_inv_cost_s = sum(C_tilde[k] * cp.maximum(sum(p[s][j][k]*y[j][k] for j in range(m)) - d[s][k], 0)\n",
    "                             for k in range(n))\n",
    "        unc_rev_s = sum(U[k] * cp.minimum(sum(p[s][j][k]*y[j][k] for j in range(m)),d[s][k]) \n",
    "                        for k in range(n))\n",
    "        constraints.append(unc_inv_cost_s - unc_rev_s - theta <= 0)\n",
    "    \n",
    "    constraints.append(cp.sum(y, axis=1) <= A)\n",
    "    \n",
    "    fixed_costs = cp.sum(cp.multiply(C, y))\n",
    "    obj = cp.Minimize(fixed_costs + theta)\n",
    "    prob = cp.Problem(obj,constraints)\n",
    "    \n",
    "    # solve problem\n",
    "    time_limit = kwargs.get('time_limit', 2*60*60)    \n",
    "    prob.solve(solver=cp.MOSEK, mosek_params = {mosek.dparam.optimizer_max_time: time_limit})\n",
    "    x_value = [theta.value, y.value] # Combine y and theta into 1 single solution vector\n",
    "    return (x_value, prob.value)\n",
    "\n",
    "def unc_obj_func(x, data, **kwargs):\n",
    "    # extract values\n",
    "    C = kwargs['C']\n",
    "    C_tilde = kwargs['C_tilde']\n",
    "    U = kwargs['U']\n",
    "    d,p = zip(*data)\n",
    "    m,n = p[0].shape\n",
    "    y = x[1]\n",
    "    \n",
    "    # compute obj function value:\n",
    "    fixed_costs = np.sum(np.multiply(C, y))\n",
    "    inv_cost = np.array([sum(C_tilde[k] * np.maximum(sum(p[s][j][k]*y[j][k] for j in range(m)) - d[s][k], 0)\n",
    "                             for k in range(n)) for s in range(len(data))]) \n",
    "    rev = np.array([sum(U[k] * np.minimum(sum(p[s][j][k]*y[j][k] for j in range(m)),d[s][k]) \n",
    "                        for k in range(n)) for s in range(len(data))]) \n",
    "    return fixed_costs + inv_cost - rev\n",
    "\n",
    "def eval_p_vio(x, obj, data, **kwargs):\n",
    "    evals = unc_obj_func(x, data, **kwargs) - obj \n",
    "    p_vio = sum(evals>(0+(1e-6))) / len(data) \n",
    "    return p_vio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide functions and other info for generating & evaluating solutions\n",
    "solve_SCP = solve_P_SCP\n",
    "problem_instance = get_fixed_param_data()\n",
    "\n",
    "eval_unc_obj = {'function': unc_obj_func,\n",
    "                'info': {'risk_measure': 'probability', # must be either 'probability' or 'expectation'\n",
    "                         'desired_rhs': 1 - 0.01}}\n",
    "\n",
    "eval_unc_constr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77480a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classic approach:\n",
    "random_seed = 0\n",
    "N = 10 #10580\n",
    "data = generate_unc_param_data(random_seed, N)\n",
    "\n",
    "start_time = time.time()\n",
    "x, obj = solve_P_SCP(data, **problem_instance)\n",
    "runtime = time.time() - start_time\n",
    "\n",
    "print(obj)\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Care (2014) approach:\n",
    "generate_unc_param_data = generate_unc_param_data\n",
    "conf_param_alpha = 1e-9\n",
    "dim_x = 5 * 10\n",
    "N_1 = 1000\n",
    "random_seed = 0\n",
    "\n",
    "x_care, obj_care, N_2, runtime = util.solve_with_care2014(solve_SCP, problem_instance, generate_unc_param_data, \n",
    "                                                    eval_unc_obj, conf_param_alpha, dim_x, N_1=N_1,\n",
    "                                                    random_seed=random_seed)\n",
    "\n",
    "print(x_care, obj_care, N_2, runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and split data into train and test\n",
    "random_seed = 0\n",
    "N_total = 10000\n",
    "data = generate_unc_param_data(random_seed, N_total)\n",
    "\n",
    "N_train = N_total / 2\n",
    "data_train, data_test = train_test_split(data, train_size=(N_train/N_total), random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7588bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our own algorithm parameter values\n",
    "conf_param_alpha = 1e-9\n",
    "add_strategy = 'random_vio'\n",
    "remove_strategy = 'random_any'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43062d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the algorithm\n",
    "alg = iter_gen_and_eval_alg(solve_SCP, problem_instance, eval_unc_obj, eval_unc_constr, \n",
    "                            data_train, data_test, conf_param_alpha=conf_param_alpha,\n",
    "                            verbose=False)\n",
    "\n",
    "\n",
    "stop_criteria={'max_elapsed_time': 1*60} # in seconds (time provided to search algorithm)\n",
    "\n",
    "(best_sol, runtime, num_iter, pareto_frontier, S_history) = alg.run(stop_criteria=stop_criteria)\n",
    "print(best_sol, runtime, num_iter, pareto_frontier, S_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e5c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d0fa288",
   "metadata": {},
   "source": [
    "# Now for the computational experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed3510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1265819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11188 9854.613981723785 456.33423839727084 0.001315\n",
      "Completed run: 1\n"
     ]
    }
   ],
   "source": [
    "output_file_name = 'var_epsilon_original_wdp_classic_seeds=1-10'\n",
    "\n",
    "headers = ['$\\epsilon$', 'seed', \n",
    "           #'$N^{Classic}$', '$T^{Classic}$', '$Obj.~(Classic)$', '$p_{vio}^{OoS}~(Classic)$', \n",
    "           '$N_1^{FAST}$', '$N_2^{FAST}$', '$T^{FAST}$', '$Obj.~(FAST)$', '$p_{vio}^{OoS}~(FAST)$', \n",
    "           '$N_1^{ISSuR}$', '$N_2^{ISSuR}$', '$T^{ISSuR}$', '$Obj.~(ISSuR)$', '$p_{vio}^{OoS}~(ISSuR)$', \n",
    "           '\\#Iter.~(\\texttt{add})', '\\#Iter.~(\\texttt{remove})', '$\\mu_{|\\mathcal{S}_i|}$']\n",
    "\n",
    "# Write headers to .txt file\n",
    "with open(r'output/WeightedDistributionProblem/headers_'+output_file_name+'.txt','w+') as f:\n",
    "    f.write(str(headers))\n",
    "\n",
    "output_data = {}\n",
    "\n",
    "epsilon_settings = [0.01]\n",
    "random_seed_settings = [i for i in range(1, 11)]\n",
    "\n",
    "# fixed info:\n",
    "solve_SCP = solve_P_SCP\n",
    "problem_instance = get_fixed_param_data()\n",
    "eval_unc_obj = {'function': unc_obj_func,\n",
    "                    'info': {'risk_measure': 'probability'}}\n",
    "eval_unc_constr = None\n",
    "conf_param_alpha = 1e-9\n",
    "dim_x = 5 * 10\n",
    "N_1 = 1000\n",
    "\n",
    "random_seed = 1234\n",
    "N_OoS = int(1e6)\n",
    "data_OoS = generate_unc_param_data(1234, N_OoS)\n",
    "\n",
    "run_count = 0\n",
    "for epsilon in epsilon_settings:\n",
    "    \n",
    "    eval_unc_obj['info']['desired_rhs'] = 1 - epsilon\n",
    "\n",
    "    for random_seed in random_seed_settings:\n",
    "\n",
    "        # classic approach:\n",
    "        N_classic = util.determine_calafiore_N_min(dim_x, 1 - epsilon, conf_param_alpha)\n",
    "        data = generate_unc_param_data(random_seed, N_classic)\n",
    "        start_time = time.time()\n",
    "        x, obj = solve_P_SCP(data, **problem_instance)\n",
    "        runtime_classic = time.time() - start_time\n",
    "        obj_classic = - obj\n",
    "        p_vio_classic = eval_p_vio(x, obj, data_OoS, **problem_instance)\n",
    "        print(N_classic, runtime_classic, obj_classic, p_vio_classic)\n",
    "        \n",
    "#         # FAST approach\n",
    "#         x, obj, N_2, runtime = util.solve_with_care2014(solve_SCP, problem_instance, generate_unc_param_data, \n",
    "#                                                     eval_unc_obj, conf_param_alpha, dim_x, N_1=N_1,\n",
    "#                                                     random_seed=random_seed)\n",
    "#         runtime_FAST = runtime \n",
    "#         obj_FAST = - obj\n",
    "#         p_vio_FAST = eval_p_vio(x, obj, data_OoS, **problem_instance)\n",
    "        \n",
    "#         # Our method\n",
    "#         N_total = N_1 + N_2\n",
    "#         data = generate_unc_param_data(random_seed, N_total)\n",
    "#         N_train = N_total / 2\n",
    "#         data_train, data_test = train_test_split(data, train_size=(N_train/N_total), random_state=random_seed)\n",
    "        \n",
    "#         alg = iter_gen_and_eval_alg(solve_SCP, problem_instance, eval_unc_obj, eval_unc_constr, \n",
    "#                                     data_train, data_test, conf_param_alpha=conf_param_alpha,\n",
    "#                                     verbose=False)\n",
    "        \n",
    "# #         stop_criteria={'max_elapsed_time': 5*60} # in seconds (time provided to search algorithm)\n",
    "#         stop_criteria={'max_elapsed_time': runtime_FAST} # in seconds (time provided to search algorithm)\n",
    "\n",
    "#         (best_sol, runtime, num_iter, pareto_frontier, S_history) = alg.run(stop_criteria=stop_criteria)\n",
    "        \n",
    "#         obj_ISSuR = - best_sol['obj']\n",
    "#         p_vio_ISSuR = eval_p_vio(best_sol['sol'], best_sol['obj'], data_OoS, **problem_instance)\n",
    "#         S_avg = sum(len(S_i) for S_i in S_history) / len(S_history)\n",
    "        \n",
    "        output_data[(epsilon, random_seed)] = [N_classic, runtime_classic, obj_classic, p_vio_classic]#,\n",
    "#                                                N_1, N_2, runtime_FAST, obj_FAST, p_vio_FAST,\n",
    "#                                                N_train, (N_total-N_train), runtime, obj_ISSuR, p_vio_ISSuR,\n",
    "#                                                num_iter['add'], num_iter['remove'], S_avg]\n",
    "\n",
    "        output_file_name = 'new_output_data'\n",
    "        with open(r'output/WeightedDistributionProblem/'+output_file_name+'.txt','w+') as f:\n",
    "            f.write(str(output_data))\n",
    "\n",
    "        run_count += 1\n",
    "        print(\"Completed run: \" + str(run_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10eada38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8274"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_str = {}\n",
    "for i,res in output_data.items():\n",
    "    res_str = []\n",
    "    for i2,el in enumerate(res):\n",
    "        if i2 in [1,2,3,6,7,8,11,12,13,16]:\n",
    "            if np.isnan(el):\n",
    "                res_str.append('-')\n",
    "            else:\n",
    "                res_str.append(f'{round(el,2):.2f}') \n",
    "        else:\n",
    "            res_str.append(f'{round(el,0):.0f}') \n",
    "    \n",
    "    output_data_str[i] = res_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataio\n",
    "dataio.write_output_to_latex(2, headers, output_data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c42298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
