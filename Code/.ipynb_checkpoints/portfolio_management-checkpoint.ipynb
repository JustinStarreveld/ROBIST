{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b1277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external packages\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import math\n",
    "\n",
    "# import internal packages\n",
    "import phi_divergence as phi\n",
    "from iter_gen_and_eval_alg import iter_gen_and_eval_alg\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496bc27",
   "metadata": {},
   "source": [
    "The problem we examine is as follows:\n",
    "\n",
    "\\begin{align}\n",
    "\\label{math_form:examples:pm2}\n",
    "    \\max_{\\mathbf{x}}&~\\theta \\\\\n",
    "    \\text{s.t.}&~\\mathbf{r}^T \\mathbf{x} \\geq \\theta \\\\\n",
    "    &~\\mathbf{e}^T \\mathbf{x} = 1, \\\\\n",
    "    &~\\mathbf{x} \\geq 0,\n",
    "\\end{align}\n",
    "\n",
    "where $\\mathbf{x}, \\mathbf{r} \\in \\mathbb{R}^{k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ac261d",
   "metadata": {},
   "source": [
    "In order to compare with Bertsimas, D., Gupta, V., & Kallus, N. (2018), we randomly generate $N$ synthetic returns for k assets, which is done as in Natarajan et al. (2008):\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{r}_{i}=\\left\\{\\begin{array}{ll}\n",
    "\\frac{\\sqrt{\\left(1-\\gamma_{i}\\right) \\gamma_{i}}}{\\gamma_{i}} & \\text { with probability } \\gamma_{i} \\\\[2mm]\n",
    "-\\frac{\\sqrt{\\left(1-\\gamma_{i}\\right) \\gamma_{i}}}{1-\\gamma_{i}} & \\text { with probability } 1-\\gamma_{i}\n",
    "\\end{array}, \\quad \\gamma_{i}=\\frac{1}{2}\\left(1+\\frac{i}{k + 1}\\right), \\quad i=1, \\ldots, k. \\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21db292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem specific functions:\n",
    "def generate_data_natarajan2008(random_seed, N, **kwargs):\n",
    "    k = kwargs['k']    \n",
    "    np.random.seed(random_seed)\n",
    "    gamma = np.fromiter((((1/2)*(1 + (i/(k+1)))) for i in range(1,k+1)), float)\n",
    "    return_pos = np.fromiter(((math.sqrt((1-gamma[i])*gamma[i])/gamma[i]) for i in range(0,k)), float)\n",
    "    return_neg = np.fromiter((-(math.sqrt((1-gamma[i])*gamma[i])/(1-gamma[i])) for i in range(0,k)), float)\n",
    "    data = np.empty([N,k])\n",
    "    for n in range(0, N):\n",
    "        for i in range(0, k):\n",
    "            prob = np.random.uniform()\n",
    "            if prob <= gamma[i]:\n",
    "                data[n, i] = return_pos[i]\n",
    "            else:\n",
    "                data[n, i] = return_neg[i]\n",
    "    return data \n",
    "\n",
    "def generate_data_mohajerin2018(random_seed, N, **kwargs):\n",
    "    k = kwargs['k']\n",
    "    np.random.seed(random_seed)\n",
    "    # NOTE: not entirely clear in Esfahani & Kuhn paper whether they refer to stdev or var\n",
    "    sys_risk_mean = 0\n",
    "    #sys_risk_stdev = math.sqrt(0.02)\n",
    "    sys_risk_stdev = 0.02\n",
    "    unsys_risk_mean = np.fromiter(((i * 0.03) for i in range(1,k+1)), float)\n",
    "    #unsys_risk_stdev = np.fromiter(( math.sqrt(i * 0.025) for i in range(1,k+1)), float)\n",
    "    unsys_risk_stdev = np.fromiter(( i * 0.025 for i in range(1,k+1)), float)\n",
    "    data = np.empty([N,k])\n",
    "    for n in range(0, N):\n",
    "        sys_return = np.random.normal(sys_risk_mean, sys_risk_stdev)\n",
    "        for i in range(0, k):\n",
    "            unsys_return = np.random.normal(unsys_risk_mean[i], unsys_risk_stdev[i])\n",
    "            data[n, i] = sys_return + unsys_return\n",
    "    return data \n",
    "\n",
    "def solve_SCP(S, **kwargs):\n",
    "    k = S.shape[1]\n",
    "    x = cp.Variable(k, nonneg = True)\n",
    "    theta = cp.Variable(1)\n",
    "    constraints = [- (S @ x) <= theta, cp.sum(x) == 1]\n",
    "    obj = cp.Minimize(theta) # must formulate as min problem\n",
    "    prob = cp.Problem(obj,constraints)\n",
    "    time_limit = kwargs.get('time_limit', 2*60*60)    \n",
    "#     prob.solve(solver=cp.MOSEK, mosek_params = {mosek.dparam.optimizer_max_time: time_limit})\n",
    "    prob.solve(solver=cp.GUROBI, verbose=False, TimeLimit=time_limit)\n",
    "    x_value = np.concatenate((theta.value,x.value)) # Combine x and theta into 1 single solution vector\n",
    "    return(x_value, prob.value)\n",
    "\n",
    "# def unc_obj_func(x, data, **kwargs):\n",
    "#     return np.dot(data,x[1:]) # Assume that x[0] contains theta variable \n",
    "\n",
    "# def eval_x_OoS(x, obj, data, eval_unc_obj, **kwargs):\n",
    "#     unc_obj_func = eval_unc_obj['function']\n",
    "#     desired_rhs = eval_unc_obj['info']['desired_rhs']\n",
    "    \n",
    "#     evals = unc_obj_func(x, data, **kwargs)  \n",
    "#     p_vio = sum(evals<(-obj+(1e-6))) / len(data) \n",
    "#     VaR = - np.quantile(evals, desired_rhs, method='inverted_cdf')\n",
    "#     return p_vio, VaR\n",
    "\n",
    "def unc_obj_func(x, data, **kwargs):\n",
    "    return - np.dot(data,x[1:]) # Assume that x[0] contains theta variable \n",
    "\n",
    "def eval_x_OoS(x, obj, data, eval_unc_obj, **kwargs):\n",
    "    unc_obj_func = eval_unc_obj['function']\n",
    "    desired_rhs = eval_unc_obj['info']['desired_rhs']\n",
    "    \n",
    "    evals = unc_obj_func(x, data, **kwargs)  \n",
    "    p_vio = sum(evals>(obj+(1e-6))) / len(data) \n",
    "    VaR = - np.quantile(evals, desired_rhs, method='inverted_cdf')\n",
    "    return p_vio, VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b56c3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calafiore2013 method:\n",
    "def solve_with_calafiore2013(solve_SCP, problem_instance, dim_x, data, risk_param_epsilon, conf_param_alpha, q=-1):\n",
    "    start_time = time.time()\n",
    "    # 1) given N, determine maximum q such that rhs of eq 12 is no greater than N\n",
    "    N = len(data)\n",
    "    z_tol_cal = risk_param_epsilon\n",
    "    n_cal = dim_x\n",
    "    beta_cal = conf_param_alpha\n",
    "    \n",
    "    if q == -1:\n",
    "        def eval_eq_12_calafiore2013(z_tol_cal, beta_cal, q, n_cal):\n",
    "            return 2/z_tol_cal * math.log(1/beta_cal) + 4/z_tol_cal * (q+n_cal)\n",
    "        \n",
    "        # do bisection search to find maximum q\n",
    "        a = 0\n",
    "        b = N - n_cal - 1\n",
    "        f_b = eval_eq_12_calafiore2013(z_tol_cal, beta_cal, b, n_cal)\n",
    "        \n",
    "        if f_b <= N:\n",
    "            q = b\n",
    "        else:\n",
    "            while True:\n",
    "                if b-a == 1:\n",
    "                    if eval_eq_12_calafiore2013(z_tol_cal, beta_cal, b, n_cal) <= N:\n",
    "                        q = b\n",
    "                        break\n",
    "                    else:\n",
    "                        q = a\n",
    "                        break\n",
    "                \n",
    "                c = math.ceil((a+b)/2)\n",
    "                f_c = eval_eq_12_calafiore2013(z_tol_cal, beta_cal, c, n_cal)\n",
    "                if f_c > N:\n",
    "                    b = c\n",
    "                else:\n",
    "                    a = c\n",
    "    \n",
    "    # 2) iteratively, using Lagrange multiplier-based rule, discard q scenarios\n",
    "    def solve_SCP_w_duals(S, **kwargs):\n",
    "        k = S.shape[1]\n",
    "        x = cp.Variable(k, nonneg = True)\n",
    "        theta = cp.Variable(1)\n",
    "        constraints = [theta - (S @ x) <= 0, cp.sum(x) == 1]\n",
    "        obj = cp.Minimize(-theta) # must formulate as min problem\n",
    "        prob = cp.Problem(obj,constraints)\n",
    "        time_limit = kwargs.get('time_limit', 2*60*60)    \n",
    "        prob.solve(solver=cp.GUROBI, verbose=False, TimeLimit=time_limit)\n",
    "        x_value = np.concatenate((theta.value,x.value)) # Combine x and theta into 1 single solution vector\n",
    "        \n",
    "        duals = constraints[0].dual_value\n",
    "        return(x_value, prob.value, duals)\n",
    "        \n",
    "    # Start with all N scenarios and remove one-by-one\n",
    "    num_removed = 0\n",
    "    while num_removed < q:\n",
    "        x, obj, duals = solve_SCP_w_duals(data, **problem_instance)\n",
    "        scen_i = np.argmax(duals)\n",
    "        data = np.delete(data, scen_i, axis=0)\n",
    "        num_removed += 1\n",
    "        \n",
    "    # return final solution\n",
    "    x, obj = solve_SCP(data, **problem_instance)\n",
    "    return x, obj, (time.time() - start_time), q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8549ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check gamma values:\n",
    "k = 10\n",
    "gamma = np.fromiter((((1/2)*(1 + (i/(k+1)))) for i in range(1,k+1)), float)\n",
    "return_pos = np.fromiter(((math.sqrt((1-gamma[i])*gamma[i])/gamma[i]) for i in range(0,k)), float)\n",
    "return_neg = np.fromiter((-(math.sqrt((1-gamma[i])*gamma[i])/(1-gamma[i])) for i in range(0,k)), float)\n",
    "print(gamma)\n",
    "print(return_pos)\n",
    "print(return_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter values (as in Bertsimas paper)\n",
    "k = 10\n",
    "conf_param_alpha = 0.10\n",
    "risk_param_epsilon = 0.10\n",
    "N_total = 500 \n",
    "N_train = int(N_total / 2)\n",
    "N_test = N_total - N_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide functions and other info for generating & evaluating solutions\n",
    "problem_instance = {}\n",
    "problem_instance['time_limit'] = 2*60*60 \n",
    "\n",
    "eval_unc_obj = {'function': unc_obj_func,\n",
    "                'info': {'risk_measure': 'probability', # must be either 'probability' or 'expectation'\n",
    "                         'desired_rhs': 1-risk_param_epsilon}}\n",
    "\n",
    "eval_unc_constr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2193d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine data generation function\n",
    "# generate_data = generate_data_natarajan2008\n",
    "generate_data = generate_data_mohajerin2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e21d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get generated data\n",
    "random_seed = 0\n",
    "data = generate_data(random_seed, N_total, k=k)\n",
    "data_train, data_test = train_test_split(data, train_size=(N_train/N_total), random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate extra out-of-sample (OoS) data\n",
    "random_seed_OoS = 1234\n",
    "N_OoS = int(1e6)\n",
    "data_OoS = generate_data(random_seed_OoS, N_OoS, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the algorithm\n",
    "alg = iter_gen_and_eval_alg(solve_SCP, problem_instance, eval_unc_obj, eval_unc_constr, \n",
    "                            data_train, data_test, conf_param_alpha=conf_param_alpha,\n",
    "                            verbose=False)\n",
    "time_limit_alg = 60\n",
    "stop_criteria={'max_elapsed_time': time_limit_alg} # in seconds (time provided to search algorithm)\n",
    "\n",
    "N2_min = alg._determine_N_min(N_test, 1-risk_param_epsilon)\n",
    "eval_unc_obj['info']['N2_min'] = N2_min\n",
    "\n",
    "(best_sol, runtime, num_iter, pareto_frontier, S_history) = alg.run(stop_criteria=stop_criteria)\n",
    "\n",
    "obj_alg = - best_sol['obj']\n",
    "p_vio_alg, VaR_alg = eval_x_OoS(best_sol['sol'], best_sol['obj'], data_OoS, eval_unc_obj, **problem_instance)\n",
    "print(N_train, N_total-N_train, runtime, obj_alg, p_vio_alg, VaR_alg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32fbed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runtime_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429175a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataio.print_solution_info(best_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VaR_bound = best_sol['sol'][0]\n",
    "VaR_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d127fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sol['sol'][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78849f94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "returns_test = np.dot(data_test, best_sol['sol'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be the emperical VaR observed on test data \n",
    "np.percentile(a=returns_test, q=100*risk_param_epsilon, method='inverted_cdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46138e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pareto_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287d75d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataio.plot_pareto_curve(pareto_solutions, beta, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c502150",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataio.plot_pareto_curve(pareto_solutions, beta, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86a966",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataio.plot_obj_over_time(solutions, best_sol, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9e83c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataio.plot_size_set_over_time(solutions, best_sol, None, None, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4308145",
   "metadata": {},
   "source": [
    "# Here we calculate the a-priori phi-divergence RO solution assuming no prior knowledge of the distribution of the returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5672ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_dot = 2 # This is the phi_dot for modified chi squared.\n",
    "phi_conj = phi.mod_chi2_conj\n",
    "r = phi_dot/(2*N)*scipy.stats.chi2.ppf(0.1, N-1)\n",
    "p = np.zeros(N)+1/N\n",
    "beta = 0.95\n",
    "print(util.af_RC_exp_pmin(p,returns,r,phi_conj,np.array([1/(1-beta),0]),np.array([0,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a26f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48e8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8602b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1433f0c8",
   "metadata": {},
   "source": [
    "# Now for the computational experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "286d66aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N campi min: 599\n",
      "Completed run: 1\n",
      "Completed run: 2\n",
      "Completed run: 3\n"
     ]
    }
   ],
   "source": [
    "output_file_name = 'pm_calafiore2013_generate_data_mohajerin2018_k=100_N=2000_eps=0.10_seeds=1-100'\n",
    "\n",
    "headers = ['seed', '$N$', '$N_1$', '$N_2$', '$T$', 'Obj.', '$p_{vio}^{OoS}$', '$VaR^{OoS}$',\n",
    "           '\\#Iter.~(\\\\texttt{add})', '\\#Iter.~(\\\\texttt{remove})', \n",
    "           '$\\mu_{|\\mathcal{S}_i|}$', '$\\max_{i}|\\mathcal{S}_i|$',\n",
    "           'N (CM)', 'q (CM)', 'runtime (CM)',\n",
    "           'Obj. (CM)', '$p_{vio}^{OoS}$ (CM)', '$VaR^{OoS}$ (CM)',]\n",
    "\n",
    "# # Write headers to .txt file\n",
    "# with open(r'output/PortfolioManagement/headers_'+output_file_name+'.txt','w+') as f:\n",
    "#     f.write(str(headers))\n",
    "\n",
    "output_data = {}\n",
    "\n",
    "# Set parameter values (as in Bertsimas paper)\n",
    "k = 100\n",
    "conf_param_alpha = 0.10\n",
    "risk_param_epsilon = 0.10\n",
    "\n",
    "N_cal_min = util.determine_campi_N_min(k, 1-risk_param_epsilon, conf_param_alpha)\n",
    "print(\"N campi min:\", N_cal_min)\n",
    "\n",
    "N_total = 2000 \n",
    "N_train = math.floor(N_total / 2)\n",
    "N_test = N_total - N_train\n",
    "\n",
    "problem_instance = {}\n",
    "problem_instance['time_limit'] = 1*60*60 \n",
    "\n",
    "eval_unc_obj = {'function': unc_obj_func,\n",
    "                'info': {'risk_measure': 'probability', # must be either 'probability' or 'expectation'\n",
    "                         'desired_rhs': 1 - risk_param_epsilon}}\n",
    "\n",
    "eval_unc_constr = None\n",
    "\n",
    "# Determine data generation function\n",
    "# generate_data = generate_data_natarajan2008\n",
    "generate_data = generate_data_mohajerin2018\n",
    "\n",
    "# Generate extra out-of-sample (OoS) data\n",
    "random_seed_OoS = 1234\n",
    "N_OoS = int(1e6)\n",
    "data_OoS = generate_data(random_seed_OoS, N_OoS, k=k)\n",
    "\n",
    "random_seed_settings = [i for i in range(1,4)] #101\n",
    "q_max = -1\n",
    "run_count = 0\n",
    "for random_seed in random_seed_settings:\n",
    "    \n",
    "    data = generate_data(random_seed, N_total, k=k)               \n",
    "    data_train, data_test = train_test_split(data, train_size=(N_train/N_total), random_state=random_seed)\n",
    "    \n",
    "\n",
    "    # our method   \n",
    "    alg = iter_gen_and_eval_alg(solve_SCP, problem_instance, eval_unc_obj, eval_unc_constr, \n",
    "                                data_train, data_test, conf_param_alpha=conf_param_alpha,\n",
    "                                verbose=False)\n",
    "    \n",
    "    stop_criteria={'max_elapsed_time': 1*60} \n",
    "    (best_sol, runtime_alg, num_iter, pareto_frontier, S_history) = alg.run(stop_criteria=stop_criteria)\n",
    "    \n",
    "    obj_alg = - best_sol['obj']\n",
    "    p_vio_alg, VaR_alg = eval_x_OoS(best_sol['sol'], best_sol['obj'], data_OoS, eval_unc_obj, **problem_instance)\n",
    "    S_avg = sum(len(S_i) for S_i in S_history) / len(S_history)\n",
    "    S_max = max(len(S_i) for S_i in S_history)\n",
    "        \n",
    "    # calafiore2013 method    \n",
    "    x, obj, runtime_cal, q = solve_with_calafiore2013(solve_SCP, problem_instance, k, data, risk_param_epsilon, \n",
    "                                                      conf_param_alpha, q=q_max)\n",
    "    obj_cal = - obj\n",
    "    q_max = q\n",
    "    p_vio_cal, VaR_cal = eval_x_OoS(x, obj, data_OoS, eval_unc_obj, **problem_instance)\n",
    "        \n",
    "    output_data[(random_seed, N_total)] = [N_train, N_test, runtime_alg, obj_alg, p_vio_alg, VaR_alg, \n",
    "                                           num_iter['add'], num_iter['remove'], S_avg, S_max,\n",
    "                                           N_total, q, runtime_cal,\n",
    "                                           obj_cal, p_vio_cal, VaR_cal]\n",
    "    \n",
    "    output_file_name = 'new_output_data'\n",
    "    with open(r'output/PortfolioManagement/'+output_file_name+'.txt','w+') as f:\n",
    "        f.write(str(output_data))\n",
    "    \n",
    "    run_count += 1\n",
    "    print(\"Completed run: \" + str(run_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887db43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "from numpy import array # add if the .txt file contains numpy arrays\n",
    "\n",
    "output_file_name = 'pm_bertsimas2018_N=500_eps=0.10_seeds=1-100'\n",
    "# Read from .txt file\n",
    "file_path = 'output/PortfolioManagement/'+output_file_name+'.txt'\n",
    "dic = ''\n",
    "with open(file_path,'r') as f:\n",
    "     for i in f.readlines():\n",
    "        if i != \"nan\":\n",
    "            dic+=i #string\n",
    "output_data_read = eval(dic)\n",
    "output_data_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666fdaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = output_data_read\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain average and std dev\n",
    "import pandas as pd\n",
    "df_output = pd.DataFrame.from_dict(output_data, orient='index')\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb57b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa2683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22ea1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in previous output from .txt file\n",
    "from numpy import array # add if the .txt file contains numpy arrays\n",
    "output_file_name = 'PM_compare_bertsimas_phidot=1_N1=250_N2=250_alpha=0.1_beta=0.9_100_seeds_L=1min'\n",
    "\n",
    "file_path = 'output/'+output_file_name+'.txt'\n",
    "dic = ''\n",
    "with open(file_path,'r') as f:\n",
    "    for i in f.readlines():\n",
    "        dic+=i\n",
    "output_data_read = eval(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data to get avg and stddev across random seed runs\n",
    "import pandas as pd\n",
    "\n",
    "output_data_agg = {}\n",
    "df_VaR = pd.DataFrame({key: pd.Series(val[5]) for key, val in output_data.items()})\n",
    "df_Sol = pd.DataFrame({key: pd.Series(val[0]) for key, val in output_data.items()})\n",
    "df_Sol = df_Sol.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d9916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VaR.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af336ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VaR.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee677476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Sol.drop(0, axis=1, inplace=True)\n",
    "df_Sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39deedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = df_Sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a07f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataio.plot_portfolio_holdings(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275ee565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e46edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597d65c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
