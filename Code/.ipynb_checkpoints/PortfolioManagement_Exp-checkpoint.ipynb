{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2dd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import mosek\n",
    "import time\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import phi_divergence as phi\n",
    "import robust_sampling as rs\n",
    "import dataio\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21acbb",
   "metadata": {},
   "source": [
    "The problem we examine is as follows (from Esfahani, P., & Kuhn, D. (2018)):\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\label{math_form:examples:pm_exp}\n",
    "    \\min_{\\mathbf{x}}&~\\mathbb{E}( - \\mathbf{r}^T \\mathbf{x} ) + \\rho \\text{CVaR}_{\\alpha}(- \\mathbf{r}^T \\mathbf{x}) \\\\\n",
    "    \\text{s.t.}&~\\mathbf{e}^T \\mathbf{x} = 1, \\\\\n",
    "    &~\\mathbf{x} \\geq 0,\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "where $\\mathbf{x}, \\mathbf{r} \\in \\mathbb{R}^{k}$\n",
    "\n",
    "We follow their derivation and define $J$ as:\n",
    "\n",
    "$$J = \\max_{k=\\{1,2\\}} a_k \\mathbf{r}^T \\mathbf{x} + b_k \\tau$$,\n",
    "\n",
    "with $a_1=-1, a_2=-1-\\frac{\\rho}{\\alpha}, b_1=\\rho$ and $b_2=\\rho\\left(1-\\frac{1}{\\alpha}\\right)$.\n",
    "\n",
    "Then the objective is: $\\min_{\\mathbf{x}}~\\mathbb{E}[J]$. Which can be transformed to epigraph formulation:\n",
    "\\begin{align}\n",
    "\\label{}\n",
    "    \\min_{\\mathbf{x}, \\tau}&~\\theta \\\\\n",
    "    \\text{s.t.}&~\\mathbb{E}[J] \\leq \\theta,\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Filling in the definition of $J$ using variable $$\\gamma = J = \\max_{k=\\{1,2\\}} a_k \\mathbf{r}^T \\mathbf{x} + b_k \\tau$$ \n",
    "\n",
    "to replace the $\\max$ function, we rewrite the problem as follows:\n",
    "\n",
    "\\begin{align}\n",
    "\\label{math_form:examples:pm_exp_2}\n",
    "    \\min_{\\mathbf{x}, \\tau}&~\\theta \\\\\n",
    "    \\text{s.t.}&~\\mathbb{E}[\\gamma] \\leq \\theta, \\\\\n",
    "    &~- \\mathbf{r}^T \\mathbf{x} + \\rho \\tau \\leq \\gamma, \\\\\n",
    "    &~(-1-(\\rho / \\alpha)) \\mathbf{r}^T \\mathbf{x} + \\rho(1- (1 / \\alpha)) \\tau \\leq \\gamma, \\\\\n",
    "    &~\\mathbf{e}^T \\mathbf{x} = 1, \\\\\n",
    "    &~\\mathbf{x} \\geq 0, \\\\\n",
    "    &~\\tau, \\theta, \\gamma \\in \\mathbb{R},\n",
    "\\end{align}\n",
    "\n",
    "Thus we have an expected value constraint of the form $\\mathbb{E}[f(\\mathbf{r}, \\mathbf{x}^*)] \\leq 0$, with $f(\\mathbf{r}, \\mathbf{x}^*) = \\gamma - \\theta = \\max_{k=\\{1,2\\}} \\{a_k \\mathbf{r}^T \\mathbf{x} + b_k \\tau \\} - \\theta$\n",
    "\n",
    "In their numerical experiments, they set $k = 10$ and generate return by assuming normally distributed systematic + unsystematic risk factors. Furthermore, they set $\\alpha = 0.2$ and $\\rho = 10$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb43a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem specific functions:\n",
    "def generate_data(random_seed, k, N):\n",
    "    np.random.seed(random_seed)\n",
    "    # NOTE: not entirely clear in Esfahani & Kuhn paper whether they refer to stdev or var\n",
    "    sys_risk_mean = 0\n",
    "    #sys_risk_stdev = math.sqrt(0.02)\n",
    "    sys_risk_stdev = 0.02\n",
    "    unsys_risk_mean = np.fromiter(((i * 0.03) for i in range(1,k+1)), float)\n",
    "    #unsys_risk_stdev = np.fromiter(( math.sqrt(i * 0.025) for i in range(1,k+1)), float)\n",
    "    unsys_risk_stdev = np.fromiter(( i * 0.025 for i in range(1,k+1)), float)\n",
    "    \n",
    "    data = np.empty([N,k])\n",
    "    for n in range(0, N):\n",
    "        sys_return = np.random.normal(sys_risk_mean, sys_risk_stdev)\n",
    "        for i in range(0, k):\n",
    "            unsys_return = np.random.normal(unsys_risk_mean[i], unsys_risk_stdev[i])\n",
    "            data[n, i] = sys_return + unsys_return\n",
    "            \n",
    "    return data \n",
    "\n",
    "def solve_P_SCP(k, S, settings):\n",
    "    time_limit = settings.get('time_limit')\n",
    "    rho = settings.get('rho', 10)\n",
    "    CVaR_alpha = settings.get('CVaR_alpha', 0.20)\n",
    "    a_1 = -1\n",
    "    b_1 = rho\n",
    "    a_2 = -1 - (rho/CVaR_alpha)\n",
    "    b_2 = rho*(1 - (1/CVaR_alpha))\n",
    "    \n",
    "    x = cp.Variable(k, nonneg = True)\n",
    "    theta = cp.Variable(1)\n",
    "    gamma = cp.Variable(1)\n",
    "    tau = cp.Variable(1)\n",
    "    \n",
    "    constraints = [gamma - theta <= 0,\n",
    "                   a_1*(S @ x) + b_1*tau - gamma <= 0, \n",
    "                   a_2*(S @ x) + b_2*tau - gamma <= 0, \n",
    "                   cp.sum(x) == 1]\n",
    "    \n",
    "    obj = cp.Maximize(-theta) #equivalent to min \\theta\n",
    "    prob = cp.Problem(obj,constraints)\n",
    "    try:\n",
    "        prob.solve(solver=cp.MOSEK, \n",
    "                   # verbose=True,\n",
    "                   mosek_params = {mosek.dparam.optimizer_max_time: time_limit}\n",
    "                   )\n",
    "    except cp.error.SolverError:\n",
    "        print(\"Note: error occured in solving SCP problem...\")\n",
    "        return(None, float('-inf'))\n",
    "    # Combine theta, tau and x into 1 single solution vector\n",
    "    x_value = np.concatenate((theta.value,tau.value,x.value))\n",
    "    # Because we are actually minimizing, we add \"-\" to obj\n",
    "    return(x_value, -prob.value)\n",
    "\n",
    "def solve_P_SAA(k, S, settings):\n",
    "    time_limit = settings.get('time_limit')\n",
    "    rho = settings.get('rho', 10)\n",
    "    CVaR_alpha = settings.get('CVaR_alpha', 0.20)\n",
    "    a_1 = -1\n",
    "    b_1 = rho\n",
    "    a_2 = -1 - (rho/CVaR_alpha)\n",
    "    b_2 = rho*(1 - (1/CVaR_alpha))\n",
    "    N = S.shape[0]\n",
    "    \n",
    "    x = cp.Variable(k, nonneg = True)\n",
    "    theta = cp.Variable(1)\n",
    "    gamma = cp.Variable(N)\n",
    "    tau = cp.Variable(1)\n",
    "    \n",
    "    constraints = [(1/N)*cp.sum(gamma) - theta <= 0,\n",
    "                   a_1*(S @ x) + b_1*tau - gamma <= 0, \n",
    "                   a_2*(S @ x) + b_2*tau - gamma <= 0, \n",
    "                   cp.sum(x) == 1]\n",
    "    \n",
    "    obj = cp.Maximize(-theta) #equivalent to min \\theta\n",
    "    prob = cp.Problem(obj,constraints)\n",
    "    try:\n",
    "        prob.solve(solver=cp.MOSEK, \n",
    "                   # verbose=True,\n",
    "                   mosek_params = {mosek.dparam.optimizer_max_time: time_limit}\n",
    "                   )\n",
    "    except cp.error.SolverError:\n",
    "        print(\"Note: error occured in solving SAA problem...\")\n",
    "        return(None, float('-inf'))\n",
    "    # Combine theta, tau and x into 1 single solution vector\n",
    "    x_value = np.concatenate((theta.value,tau.value,x.value))\n",
    "    # Because we are actually minimizing, we add \"-\" to obj\n",
    "    return(x_value, -prob.value)\n",
    "\n",
    "def unc_func(data, x, settings):\n",
    "    rho = settings.get('rho', 10)\n",
    "    CVaR_alpha = settings.get('CVaR_alpha', 0.20)\n",
    "    a_1 = -1\n",
    "    b_1 = rho\n",
    "    a_2 = -1 - (rho/CVaR_alpha)\n",
    "    b_2 = rho*(1 - (1/CVaR_alpha))\n",
    "    # Assume that x[0] contains theta and x[1] contains tau\n",
    "    constr1 = a_1*np.dot(data,x[2:]) + b_1*x[1] \n",
    "    constr2 = a_2*np.dot(data,x[2:]) + b_2*x[1] \n",
    "    return np.maximum(constr1, constr2)\n",
    "\n",
    "def compute_prob_add(lhs_constr):\n",
    "    method = 'deterministic_w_1%'\n",
    "    if method == 'deterministic':\n",
    "        if lhs_constr <= 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    elif method == 'deterministic_w_1%':\n",
    "        if lhs_constr <= 0:\n",
    "            return 0.01\n",
    "        else:\n",
    "            return 0.99\n",
    "    elif method == 'sigmoid':\n",
    "        return util.compute_prob_add_sigmoid(lhs_constr)\n",
    "    else:\n",
    "        print('Error: do not recognize method in \"compute_prob_add\" function')\n",
    "        return 1\n",
    "    \n",
    "def stopping_cond(stop_info, elapsed_time, num_solutions):\n",
    "    if (elapsed_time > stop_info.get('max_elapsed_time', 10e12) \n",
    "        or num_solutions > stop_info.get('max_num_solutions', 10e12)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def emp_eval(x, data, settings):\n",
    "    rho = settings.get('rho', 10)\n",
    "    CVaR_alpha = settings.get('CVaR_alpha', 0.20)\n",
    "    x_sol = x[2:]\n",
    "    emp_returns = - (np.dot(data, x_sol))\n",
    "    exp_loss = np.mean(emp_returns, dtype=np.float64)\n",
    "    VaR = np.quantile(emp_returns, 1-CVaR_alpha, method='inverted_cdf') # gets threshold for top CVaR_alpha-% highest losses\n",
    "    above_VaR = (emp_returns > VaR)\n",
    "    cVaR = np.mean(emp_returns[above_VaR])\n",
    "    return exp_loss + (rho*cVaR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCP vs SAA\n",
    "k = 10\n",
    "rho = 10\n",
    "CVaR_alpha = 0.20\n",
    "problem_info = {'rho': rho, \n",
    "                'CVaR_alpha': CVaR_alpha,\n",
    "                'risk_measure': 'expectation', # options: 'probability'/'expectation'\n",
    "                'time_limit': 10*60}\n",
    "\n",
    "random_seed_settings = [i for i in range(2)] \n",
    "N_settings = [10, 100, 1000, 10000, 100000]\n",
    "cert = [[] for i in range(len(N_settings))]\n",
    "perf = [[] for i in range(len(N_settings))]\n",
    "\n",
    "data_eval = generate_data(999, k, 1000000)\n",
    "for random_seed in random_seed_settings:\n",
    "    for i,N in enumerate(N_settings):\n",
    "        data = generate_data(random_seed, k, N)\n",
    "#         sol, obj = solve_P_SCP(k, data, problem_info)\n",
    "        sol, obj = solve_P_SAA(k, data, problem_info)        \n",
    "        cert[i].append(obj)\n",
    "        perf[i].append(emp_eval_obj(sol, data_eval, problem_info))\n",
    "\n",
    "for i,N in enumerate(N_settings):   \n",
    "    print(f'{round(np.mean(cert[i]),3):.3f}',\"(\" + f'{round(np.std(cert[i]),3):.3f}' + \")\", \n",
    "          f'{round(np.mean(perf[i]),3):.3f}',\"(\" + f'{round(np.std(perf[i]),3):.3f}' + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test obj eval functions with equal weighted portfolio:\n",
    "k = 10\n",
    "x = np.array([None, None, None] + [1/k for i in range(k)])\n",
    "rho = 10\n",
    "CVaR_alpha = 0.20\n",
    "\n",
    "for N in [1000, 10000, 50000]:\n",
    "#     data = generate_data(66 + 99, k, N)\n",
    "#     obj_1 = emp_eval_obj(x, data, rho, CVaR_alpha)\n",
    "#     print(obj_1)\n",
    "    \n",
    "    print(\"----------------\")\n",
    "    data_2 = generate_data(66 + 99, k, N)\n",
    "    obj_2 = emp_eval_obj(x, data_2, rho, CVaR_alpha)\n",
    "    print(obj_2)\n",
    "    \n",
    "    print(\"----------------\")\n",
    "    obj_3 = analytic_out_perf(x, rho, CVaR_alpha)\n",
    "    print(obj_3)\n",
    "\n",
    "# data gen 2 seems more accurate (if analytic_out_perf is correct)\n",
    "# Not sure why there is still a slight difference... \n",
    "# suspect that there is a mistake in analytic cVaR because empirical evaluation seems sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b7922bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter values (as in Kuhn paper)\n",
    "k = 10\n",
    "rho = 10\n",
    "CVaR_alpha = 0.20\n",
    "problem_info = {'rho': rho, \n",
    "                'CVaR_alpha': CVaR_alpha,\n",
    "                'risk_measure': 'expectation', # options: 'probability'/'expectation'\n",
    "                'time_limit': 10*60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392d9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our own algorithm parameter values\n",
    "conf_param_alpha = 0.05\n",
    "N_total = 3000 # 30, 300, 3000\n",
    "N_train = int(N_total / 2)\n",
    "N_test = N_total - N_train\n",
    "bound_settings = {'min_num_obs_per_bin': 5,\n",
    "                  'num_bins_range': [10,min(20, math.floor(N_test/5))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ef7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set other parameter values\n",
    "phi_div = phi.mod_chi2_cut\n",
    "phi_dot = 2\n",
    "numeric_precision = 1e-6 # To correct for floating-point math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff5d26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get generated data\n",
    "random_seed = 0\n",
    "data = generate_data(random_seed, k, N_total)   \n",
    "data_train, data_test = train_test_split(data, train_size=(N_train/N_total), random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a2b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL:\n",
    "N_eval = 50000\n",
    "data_eval = generate_data(random_seed + 99, k, N_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df66fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "iter     : 1\n",
      "size_S   : 1\n",
      "obj_S    : -3.345\n",
      "obj_eval : 0.196\n",
      "obj_train: 0.136\n",
      "obj_test : 0.031\n",
      "p_eval   : 2.118\n",
      "b_train  : 4.337\n",
      "b_test : 4.182\n",
      "-----------------\n",
      "iter     : 2\n",
      "size_S   : 2\n",
      "obj_S    : -2.243\n",
      "obj_eval : -0.339\n",
      "obj_train: -0.392\n",
      "obj_test : -0.450\n",
      "p_eval   : 0.151\n",
      "b_train  : 1.570\n",
      "b_test : 1.588\n",
      "-----------------\n",
      "iter     : 3\n",
      "size_S   : 3\n",
      "obj_S    : -1.876\n",
      "obj_eval : -0.496\n",
      "obj_train: -0.515\n",
      "obj_test : -0.511\n",
      "p_eval   : -0.156\n",
      "b_train  : 0.939\n",
      "b_test : 1.206\n",
      "-----------------\n",
      "iter     : 4\n",
      "size_S   : 4\n",
      "obj_S    : -1.786\n",
      "obj_eval : -0.920\n",
      "obj_train: -0.910\n",
      "obj_test : -1.005\n",
      "p_eval   : -0.812\n",
      "b_train  : 0.078\n",
      "b_test : 0.139\n",
      "-----------------\n",
      "iter     : 5\n",
      "size_S   : 5\n",
      "obj_S    : -1.495\n",
      "obj_eval : -0.847\n",
      "obj_train: -0.873\n",
      "obj_test : -0.862\n",
      "p_eval   : -0.844\n",
      "b_train  : -0.007\n",
      "b_test : 0.135\n",
      "-----------------\n",
      "iter     : 6\n",
      "size_S   : 6\n",
      "obj_S    : -1.491\n",
      "obj_eval : -0.847\n",
      "obj_train: -0.873\n",
      "obj_test : -0.862\n",
      "p_eval   : -0.844\n",
      "b_train  : -0.007\n",
      "b_test : 0.135\n",
      "-----------------\n",
      "iter     : 7\n",
      "size_S   : 7\n",
      "obj_S    : -1.330\n",
      "obj_eval : -1.198\n",
      "obj_train: -1.167\n",
      "obj_test : -1.179\n",
      "p_eval   : -1.122\n",
      "b_train  : -0.329\n",
      "b_test : -0.583\n",
      "-----------------\n",
      "iter     : 8\n",
      "size_S   : 8\n",
      "obj_S    : -1.321\n",
      "obj_eval : -1.185\n",
      "obj_train: -1.156\n",
      "obj_test : -1.170\n",
      "p_eval   : -1.113\n",
      "b_train  : -0.319\n",
      "b_test : -0.567\n",
      "-----------------\n",
      "iter     : 9\n",
      "size_S   : 9\n",
      "obj_S    : -1.320\n",
      "obj_eval : -1.185\n",
      "obj_train: -1.156\n",
      "obj_test : -1.170\n",
      "p_eval   : -1.113\n",
      "b_train  : -0.319\n",
      "b_test : -0.567\n",
      "-----------------\n",
      "iter     : 10\n",
      "size_S   : 10\n",
      "obj_S    : -1.251\n",
      "obj_eval : -1.068\n",
      "obj_train: -1.064\n",
      "obj_test : -1.073\n",
      "p_eval   : -1.007\n",
      "b_train  : -0.212\n",
      "b_test : -0.375\n",
      "-----------------\n",
      "iter     : 11\n",
      "size_S   : 11\n",
      "obj_S    : -1.134\n",
      "obj_eval : -1.246\n",
      "obj_train: -1.224\n",
      "obj_test : -1.206\n",
      "p_eval   : -1.065\n",
      "b_train  : -0.310\n",
      "b_test : -0.466\n",
      "-----------------\n",
      "iter     : 12\n",
      "size_S   : 12\n",
      "obj_S    : -1.133\n",
      "obj_eval : -1.246\n",
      "obj_train: -1.225\n",
      "obj_test : -1.206\n",
      "p_eval   : -1.065\n",
      "b_train  : -0.312\n",
      "b_test : -0.467\n",
      "-----------------\n",
      "iter     : 13\n",
      "size_S   : 13\n",
      "obj_S    : -1.128\n",
      "obj_eval : -1.241\n",
      "obj_train: -1.224\n",
      "obj_test : -1.203\n",
      "p_eval   : -1.065\n",
      "b_train  : -0.319\n",
      "b_test : -0.473\n",
      "-----------------\n",
      "iter     : 14\n",
      "size_S   : 14\n",
      "obj_S    : -1.127\n",
      "obj_eval : -1.240\n",
      "obj_train: -1.223\n",
      "obj_test : -1.202\n",
      "p_eval   : -1.065\n",
      "b_train  : -0.315\n",
      "b_test : -0.471\n",
      "-----------------\n",
      "iter     : 15\n",
      "size_S   : 15\n",
      "obj_S    : -1.081\n",
      "obj_eval : -1.275\n",
      "obj_train: -1.263\n",
      "obj_test : -1.253\n",
      "p_eval   : -1.056\n",
      "b_train  : -0.435\n",
      "b_test : -0.593\n",
      "-----------------\n",
      "iter     : 16\n",
      "size_S   : 16\n",
      "obj_S    : -1.077\n",
      "obj_eval : -1.238\n",
      "obj_train: -1.235\n",
      "obj_test : -1.227\n",
      "p_eval   : -1.077\n",
      "b_train  : -0.501\n",
      "b_test : -0.639\n",
      "-----------------\n",
      "iter     : 17\n",
      "size_S   : 17\n",
      "obj_S    : -1.078\n",
      "obj_eval : -1.233\n",
      "obj_train: -1.231\n",
      "obj_test : -1.222\n",
      "p_eval   : -1.073\n",
      "b_train  : -0.491\n",
      "b_test : -0.629\n"
     ]
    }
   ],
   "source": [
    "stop_info = {'max_elapsed_time': 1*60, # in seconds (time provided to search algorithm)\n",
    "             'max_num_solutions': 10000}\n",
    "use_tabu = False # Determines whether the tabu list are used in the search\n",
    "\n",
    "add_strategy = 'random_vio'\n",
    "remove_strategy = 'random_any'\n",
    "clean_strategy = None #(100, 'all_inactive') \n",
    "\n",
    "# Sets the Problem to be solved at each iteration\n",
    "# solve_P = solve_P_SCP\n",
    "solve_P = solve_P_SAA\n",
    "\n",
    "(runtime, \n",
    " num_iter, \n",
    " solutions, \n",
    " best_sol, \n",
    " pareto_solutions) = rs.gen_and_eval_alg_obj(solve_P, unc_func, problem_info,\n",
    "                                             data_train, data_test, conf_param_alpha, \n",
    "                                             bound_settings, phi_div, phi_dot,\n",
    "                                             stopping_cond, stop_info, compute_prob_add,\n",
    "                                             add_strategy, remove_strategy, clean_strategy, \n",
    "                                             use_tabu, numeric_precision, random_seed, \n",
    "                                             data_eval, emp_eval, \n",
    "                                             analytic_out_perf=None,\n",
    "                                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae78fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = best_sol['sol']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16355bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sol['bound_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa0b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate obj emperically using data_eval\n",
    "emp_eval_obj(x, data_eval, problem_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da0f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ddd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = x[2:]\n",
    "dataio.plot_single_portfolio_holdings(x_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bfbb4d",
   "metadata": {},
   "source": [
    "# The following cells are used to obtain output and write to latex tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace1e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter values (as in Kuhn paper)\n",
    "k = 10\n",
    "rho = 10\n",
    "CVaR_alpha = 0.20\n",
    "problem_info = {'rho': rho, \n",
    "                    'CVaR_alpha': CVaR_alpha,\n",
    "                    'risk_measure': 'expectation', # options: 'probability'/'expectation'\n",
    "                    'time_limit': 10*60}\n",
    "\n",
    "# Set our own algorithm parameter values\n",
    "N_eval = 1000000\n",
    "data_eval = generate_data(999, k, N_eval)\n",
    "\n",
    "# Set other parameter values\n",
    "phi_div = phi.mod_chi2_cut\n",
    "phi_dot = 2\n",
    "numeric_precision = 1e-6 # To correct for floating-point math operations\n",
    "\n",
    "time_limit_search = 10*60 # in seconds (time provided to search algorithm)\n",
    "max_nr_solutions = 10000 # for easy problems with long time limits, we may want extra restriction\n",
    "use_tabu = False # Determines whether the tabu list are used in the search\n",
    "\n",
    "add_strategy = 'random_vio'\n",
    "remove_strategy = 'random_any'\n",
    "clean_strategy = (999999, 'all_inactive') # set arbitrarily high such that it never occurs\n",
    "\n",
    "# Sets the Problem to be solved at each iteration\n",
    "solve_P = solve_P_SCP\n",
    "# solve_P = solve_P_SAA\n",
    "conf_param_alpha = 0.50\n",
    "N_settings = [3000]\n",
    "random_seed_settings = [i for i in range(3)]\n",
    "\n",
    "for N_total in N_settings:\n",
    "    vec_obj_Cert = []\n",
    "    vec_obj_OoS = []\n",
    "    \n",
    "    count_runs = 1\n",
    "    for random_seed in random_seed_settings:\n",
    "        N_train = int(N_total / 2)\n",
    "        N_test = N_total - N_train\n",
    "        bound_settings = {'min_num_obs_per_bin': 5,\n",
    "                          'num_bins_range': [min(5, math.floor(min(N_train,N_test)/5)-1), \n",
    "                                             min(20, math.floor(min(N_train,N_test)/5))]}\n",
    "        data = generate_data(random_seed, k, N_total)   \n",
    "        data_train, data_test = train_test_split(data, train_size=(N_train/N_total), random_state=random_seed)   \n",
    "\n",
    "        (runtime, \n",
    "         num_iter, \n",
    "         solutions, \n",
    "         best_sol, \n",
    "         pareto_solutions) = rs.gen_and_eval_alg_obj(solve_P, unc_func, problem_info,\n",
    "                                                     data_train, data_test, conf_param_alpha, \n",
    "                                                     bound_settings, phi_div, phi_dot,\n",
    "                                                     time_limit_search, \n",
    "                                                     max_nr_solutions, add_strategy, \n",
    "                                                     remove_strategy, clean_strategy, \n",
    "                                                     util.compute_prob_add, use_tabu,\n",
    "                                                     numeric_precision, random_seed, \n",
    "                                                     data_eval, emp_eval_obj, \n",
    "                                                     analytic_out_perf=None,\n",
    "                                                     verbose=False)\n",
    "\n",
    "        if best_sol['sol'] is not None:                                                   \n",
    "            obj = best_sol['bound_test']\n",
    "            vec_obj_Cert.append(obj)\n",
    "            eval_true_obj = emp_eval_obj(best_sol['sol'], data_eval, problem_info)\n",
    "            vec_obj_OoS.append(eval_true_obj)\n",
    "\n",
    "    #         print(\"-----------------\")\n",
    "            print(count_runs)\n",
    "        else:\n",
    "            print(str(count_runs) + \": No feasible solution found\")\n",
    "        \n",
    "        count_runs += 1\n",
    "        \n",
    "    print(\"-----------------\")\n",
    "    print(N_total)\n",
    "    print(\"-----------------\")\n",
    "    print(f'{round(np.mean(vec_obj_Cert),3):.3f}'+\"(\" + f'{round(np.std(vec_obj_Cert),3):.3f}' + \")\")\n",
    "    print(f'{round(np.mean(vec_obj_OoS),3):.3f}'+\"(\" + f'{round(np.std(vec_obj_OoS),3):.3f}' + \")\")\n",
    "    print(\"-----------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b508664",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{round(np.mean(vec_obj_Cert),3):.3f}'+\"(\" + f'{round(np.std(vec_obj_Cert),3):.3f}' + \")\")\n",
    "print(f'{round(np.mean(vec_obj_OoS),3):.3f}'+\"(\" + f'{round(np.std(vec_obj_OoS),3):.3f}' + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fd9fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db35a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(rs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
